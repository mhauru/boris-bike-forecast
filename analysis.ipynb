{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Boris Bike usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2010, Transport for London (TfL) has been operating a city bike scheme. It was originally called Barclays Cycle Hire and is now officially known as Santander Cycles, but is more colloquially known as Boris Bikes, after then London mayor Boris Johnson. The system includes more than 10,000 bikes and hundreds of stations. With a credit card, one can go to station, rent a bike for a time, and return it to any of the other stations in London. Transport for London makes public usage data of Boris Bikes since 2012, and in this notebook I study that data. The goal is to\n",
    "* create a model for predicting the number of bikes leaving and arriving at each station, using both periodic and autoregressive features in the data and possibly weather data for London,\n",
    "* see whether the weather data is a useful predictor, by testing the hypothesis that it affects bike usage.\n",
    "\n",
    "Weather data for London is kindly provided for free by America's [National Oceanic and Atmospheric Administration](https://www.ncdc.noaa.gov/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick shout out to a couple of other interesting analyses of the same bike data that I found, that take a more exploratory tone and focus on different aspects: [Anders Ohrn](https://medium.com/@AJOhrn/data-footprint-of-bike-sharing-in-london-be9e11425248) has, among things, some cool animated maps of when and where bikes are used; [charlie1347](https://github.com/charlie1347/TfL_bikes) for instance divides stations in to two categories based on whether they see incoming trafic in the morning and outgoing in the afternoon or the other way around, and looks at the effect London tube strikes had on bike usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to hopefully giving some insight into Boris Bike usage, this project is also a vehicle for me to learn some machine learning and statistical modelling, and usage of relevant Python packages, such as scikit-learn and statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, svm, neighbors, tree\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "try:\n",
    "    import xlrd\n",
    "except Exception as e:\n",
    "    msg = (\n",
    "        \"Please install the package xlrd: `pip install --user xlrd`\"\n",
    "        \"It's an optional requirement for pandas, and we'll be needing it.\"\n",
    "    )\n",
    "    print(msg)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pretty and exportable matplotlib plots.\n",
    "# If you are running this yourself and want interactivity,\n",
    "# try `%matplotlib widget` instead.\n",
    "# set_matplotlib_formats(\"svg\")\n",
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "# Set a consistent plotting style across the notebook using Seaborn.\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and cleaning the bike data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting anywhere with it, we'll need to process the bike data quite a bit. The data comes in CSV files, each of which covers a period of time. Up first, we need to download the data from the TfL website. If you are running this code yourself, here's a script that does that. Be warned though, it's almost seven gigs of data. You can run it repeatedly though, and it won't redownload, although it will reunzip the zip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikefolder = \"./data/bikes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have 01aJourneyDataExtract10Jan16-23Jan16.csv\n",
      "Already have 01bJourneyDataExtract24Jan16-06Feb16.csv\n",
      "Already have 02bJourneyDataExtract21Feb16-05Mar2016.csv\n",
      "Already have 03JourneyDataExtract06Mar2016-31Mar2016.csv\n",
      "Already have 04JourneyDataExtract01Apr2016-30Apr2016.csv\n",
      "Already have 05JourneyDataExtract01May2016-17May2016.csv\n",
      "Already have 07JourneyDataExtract25May2016-31May2016.csv\n",
      "Already have 08JourneyDataExtract01Jun2016-07Jun2016.csv\n",
      "Already have 09JourneyDataExtract08Jun2016-14Jun2016.csv\n",
      "Already have 10JourneyDataExtract15Jun2016-21Jun2016.csv\n",
      "Already have 11JourneyDataExtract22Jun2016-28Jun2016.csv\n",
      "Already have 12JourneyDataExtract29Jun2016-05Jul2016.csv\n",
      "Already have 13JourneyDataExtract06Jul2016-12Jul2016.csv\n",
      "Already have 14JourneyDataExtract13Jul2016-19Jul2016.csv\n",
      "Already have 15JourneyDataExtract20Jul2016-26Jul2016.csv\n",
      "Already have 16JourneyDataExtract27Jul2016-02Aug2016.csv\n",
      "Already have 17JourneyDataExtract03Aug2016-09Aug2016.csv\n",
      "Already have 18JourneyDataExtract10Aug2016-16Aug2016.csv\n",
      "Already have 19JourneyDataExtract17Aug2016-23Aug2016.csv\n",
      "Already have 1a.JourneyDataExtract04Jan15-17Jan15.csv\n",
      "Already have 1b.JourneyDataExtract18Jan15-31Jan15.csv\n",
      "Already have 20JourneyDataExtract24Aug2016-30Aug2016.csv\n",
      "Already have 21JourneyDataExtract31Aug2016-06Sep2016.csv\n",
      "Already have 22JourneyDataExtract07Sep2016-13Sep2016.csv\n",
      "Already have 23JourneyDataExtract14Sep2016-20Sep2016.csv\n",
      "Already have 24JourneyDataExtract21Sep2016-27Sep2016.csv\n",
      "Already have 25JourneyDataExtract28Sep2016-04Oct2016.csv\n",
      "Already have 26JourneyDataExtract05Oct2016-11Oct2016.csv\n",
      "Already have 27JourneyDataExtract12Oct2016-18Oct2016.csv\n",
      "Already have 28JourneyDataExtract19Oct2016-25Oct2016.csv\n",
      "Already have 29JourneyDataExtract26Oct2016-01Nov2016.csv\n",
      "Already have 2a.JourneyDataExtract01Feb15-14Feb15.csv\n",
      "Already have 2b.JourneyDataExtract15Feb15-28Feb15.csv\n",
      "Already have 30JourneyDataExtract02Nov2016-08Nov2016.csv\n",
      "Already have 31JourneyDataExtract09Nov2016-15Nov2016.csv\n",
      "Already have 32JourneyDataExtract16Nov2016-22Nov2016.csv\n",
      "Already have 33JourneyDataExtract23Nov2016-29Nov2016.csv\n",
      "Already have 34JourneyDataExtract30Nov2016-06Dec2016.csv\n",
      "Already have 35JourneyDataExtract07Dec2016-13Dec2016.csv\n",
      "Already have 36JourneyDataExtract14Dec2016-20Dec2016.csv\n",
      "Already have 37JourneyDataExtract21Dec2016-27Dec2016.csv\n",
      "Already have 38JourneyDataExtract28Dec2016-03Jan2017.csv\n",
      "Already have 39JourneyDataExtract04Jan2017-10Jan2017.csv\n",
      "Already have 3a.JourneyDataExtract01Mar15-15Mar15.csv\n",
      "Already have 3b.JourneyDataExtract16Mar15-31Mar15.csv\n",
      "Already have 40JourneyDataExtract11Jan2017-17Jan2017.csv\n",
      "Already have 41JourneyDataExtract18Jan2017-24Jan2017.csv\n",
      "Already have 42JourneyDataExtract25Jan2017-31Jan2017.csv\n",
      "Already have 43JourneyDataExtract01Feb2017-07Feb2017.csv\n",
      "Already have 44JourneyDataExtract08Feb2017-14Feb2017.csv\n",
      "Already have 45JourneyDataExtract15Feb2017-21Feb2017.csv\n",
      "Already have 46JourneyDataExtract22Feb2017-28Feb2017.csv\n",
      "Already have 47JourneyDataExtract01Mar2017-07Mar2017.csv\n",
      "Already have 48JourneyDataExtract08Mar2017-14Mar2017.csv\n",
      "Already have 4a.JourneyDataExtract01Apr15-16Apr15.csv\n",
      "Already have 4b.JourneyDataExtract 17Apr15-02May15.csv\n",
      "Already have 50 Journey Data Extract 22Mar2017-28Mar2017.csv\n",
      "Already have 51 Journey Data Extract 29Mar2017-04Apr2017.csv\n",
      "Already have 52 Journey Data Extract 05Apr2017-11Apr2017.csv\n",
      "Already have 53JourneyDataExtract12Apr2017-18Apr2017.csv\n",
      "Already have 54JourneyDataExtract19Apr2017-25Apr2017.csv\n",
      "Already have 55JourneyData Extract26Apr2017-02May2017.csv\n",
      "Already have 56JourneyDataExtract 03May2017-09May2017.csv\n",
      "Already have 57JourneyDataExtract10May2017-16May2017.csv\n",
      "Already have 5a.JourneyDataExtract03May15-16May15.csv\n",
      "Already have 5b.JourneyDataExtract17May15-30May15.csv\n",
      "Already have 6aJourneyDataExtract31May15-12Jun15.csv\n",
      "Already have 6bJourneyDataExtract13Jun15-27Jun15.csv\n",
      "Already have 7a.JourneyDataExtract28Jun15-11Jul15.csv\n",
      "Already have 7b.JourneyDataExtract12Jul15-25Jul15.csv\n",
      "Already have 9a-Journey-Data-Extract-23Aug15-05Sep15.csv\n",
      "Already have 9b-Journey-Data-Extract-06Sep15-19Sep15.csv\n",
      "Already have cyclehireusagestats-2012.zip\n",
      "Unziping data/bikezips/cyclehireusagestats-2012.zip\n",
      "Already have cyclehireusagestats-2013.zip\n",
      "Unziping data/bikezips/cyclehireusagestats-2013.zip\n",
      "Already have cyclehireusagestats-2014.zip\n",
      "Unziping data/bikezips/cyclehireusagestats-2014.zip\n",
      "Already have 2015TripDatazip.zip\n",
      "Unziping data/bikezips/2015TripDatazip.zip\n",
      "Already have 2016TripDataZip.zip\n",
      "Unziping data/bikezips/2016TripDataZip.zip\n",
      "Already have 49JourneyDataExtract15Mar2017-21Mar2017.xlsx\n",
      "Converting .xlsx to .csv.\n"
     ]
    }
   ],
   "source": [
    "def download_file(datafolder, url):\n",
    "    \"\"\"Download the data from the given URL into the datafolder, unless it's\n",
    "    already there. Return path to downloaded file.\n",
    "    \"\"\"\n",
    "    datafolder = Path(datafolder)\n",
    "    datafolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    a = urlparse(url)\n",
    "    filename = Path(os.path.basename(a.path))\n",
    "    filepath = datafolder / filename\n",
    "    # Don't redownload if we already have this file.\n",
    "    if filepath.exists():\n",
    "        print(\"Already have {}\".format(filename))\n",
    "    else:\n",
    "        print(\"Downloading {}\".format(filename))\n",
    "        rqst = requests.get(url)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(rqst.content)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "# Most files are individual CSV files, listed in bike_data_urls.txt. Download\n",
    "# them.\n",
    "urlsfile = \"bike_data_urls.txt\"\n",
    "with open(urlsfile, \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "# There are a few comments in the file, marked by lines starting with #.\n",
    "# Filter them out.\n",
    "urls = [u for u in urls if u[0] != \"#\"]\n",
    "for url in urls:\n",
    "    download_file(bikefolder, url)\n",
    "\n",
    "# The early years come in zips. Download and unzip them.\n",
    "zipsfolder = Path(\"./data/bikezips\")\n",
    "bikezipurls = [\n",
    "    \"http://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2012.zip\",\n",
    "    \"http://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2013.zip\",\n",
    "    \"http://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2014.zip\",\n",
    "    \"http://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\",\n",
    "    \"http://cycling.data.tfl.gov.uk/usage-stats/2016TripDataZip.zip\",\n",
    "]\n",
    "for url in bikezipurls:\n",
    "    zippath = download_file(zipsfolder, url)\n",
    "    print(\"Unziping {}\".format(zippath))\n",
    "    with zipfile.ZipFile(zippath, \"r\") as z:\n",
    "        z.extractall(bikefolder)\n",
    "\n",
    "# Finally, there's an odd one out: One week's data comes in as an .xlsx.\n",
    "# Download and use pandas to convert it to csv.\n",
    "xlsxurl = \"https://cycling.data.tfl.gov.uk/usage-stats/49JourneyDataExtract15Mar2017-21Mar2017.xlsx\"\n",
    "xlsxfile = download_file(bikefolder, xlsxurl)\n",
    "csvfile = xlsxfile.with_suffix(\".csv\")\n",
    "print(\"Converting .xlsx to .csv.\")\n",
    "pd.read_excel(xlsxfile).to_csv(csvfile, date_format=\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have now lists on each line of the CSV file a single bike trip, with starting point and time, end point and time, and things like bike ID number. That's not quite what I'm interested in. What I want is a pandas DataFrame that has for each bike station a column for starts and ends, and as its index time. We choose to bin the time by hours. Each cell would then tell how many bikes left or arrived to this station at during a given hour.\n",
    "\n",
    "Doing this is complicated by the CSV files having quite inconsistent formatting. Date formats vary, stations go by different names, etc. If you care about all the details of what needs to be done to get this cleaned up, read the source code below.\n",
    "\n",
    "Finally, since processing this data takes a few minutes, we store the resulting DataFrame in a file in the current working directory. You can then run this cell again, and it'll just load that file. It takes up around 600Mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminology for the code: An `event` is when a bike either arrives or leaves a station.\n",
    "\n",
    "\n",
    "def add_station_names(station_names, df, namecolumn, idcolumn):\n",
    "    \"\"\"Given a DataFrame df that has df[namecolumn] listing names of stations and\n",
    "    df[idcolumn] listing station ID numbers, add to the dictionary station_names\n",
    "    all the names that each ID is attached to.\n",
    "    \"\"\"\n",
    "    namemaps = (\n",
    "        df[[idcolumn, namecolumn]]\n",
    "        .groupby(idcolumn)\n",
    "        .aggregate(lambda x: x.unique())\n",
    "    )\n",
    "    for number, names in namemaps.iterrows():\n",
    "        current_names = station_names.get(number, set())\n",
    "        # The following two lines are a stupid dance around the annoying fact that pd.unique sometimes returns a single value,\n",
    "        # sometimes a numpy array of values, but since the single value is a string, it too is an iterable.\n",
    "        vals = names[0]\n",
    "        new_names = set([vals]) if type(vals) == str else set(vals)\n",
    "        current_names.update(new_names)\n",
    "        station_names[number] = current_names\n",
    "\n",
    "\n",
    "def clean_datetime_column(df, colname, roundto=\"H\"):\n",
    "    \"\"\"Parse df[colname] from strings to datetime objects, and round the\n",
    "    times to the nearest hour. Also chop off from df any rows with times before 2010-7-30 or\n",
    "    after 2020-1-1, since these are nonsense. df is partially modified in place, but the return value\n",
    "    should still be used.\n",
    "    \"\"\"\n",
    "    # A bit of a hacky way to use the first entry to figure out which date format this file uses.\n",
    "    # Not super robust, but works. TODO Improve this.\n",
    "    if len(df[colname].iloc[0]) > 16:\n",
    "        format = \"%d/%m/%Y %H:%M:%S\"\n",
    "    else:\n",
    "        format = \"%d/%m/%Y %H:%M\"\n",
    "    df[colname] = pd.to_datetime(df[colname], format=format)\n",
    "    df[colname] = df[colname].dt.round(roundto)\n",
    "    early_cutoff = pd.datetime(2010, 7, 30)  # When the program started.\n",
    "    late_cutoff = pd.datetime(2020, 1, 1)  # Approximately now.\n",
    "    df = df[(late_cutoff > df[colname]) & (df[colname] >= early_cutoff)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_single_events(df, which):\n",
    "    \"\"\"Read from df all the events, either starts or stops depending on `which`, and\n",
    "    collect them in a DataFrame that lists event counts per station and time.\n",
    "    \"\"\"\n",
    "    stationcol = \"{}Station Id\".format(which)\n",
    "    datecol = \"{} Date\".format(which)\n",
    "    events = (\n",
    "        df.rename(columns={stationcol: \"Station\", datecol: \"Date\"})\n",
    "        .groupby([\"Date\", \"Station\"])\n",
    "        .size()\n",
    "        .unstack(\"Station\")\n",
    "    )\n",
    "    return events\n",
    "\n",
    "\n",
    "def compute_both_events(df):\n",
    "    \"\"\"Read from df all the events, both starts and ends, and\n",
    "    collect them in a DataFrame that lists event counts per station and time.\n",
    "    \"\"\"\n",
    "    ends = compute_single_events(df, \"End\")\n",
    "    starts = compute_single_events(df, \"Start\")\n",
    "    both = (\n",
    "        pd.concat([ends, starts], keys=[\"End\", \"Start\"], axis=1)\n",
    "        .reorder_levels([1, 0], axis=1)\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "    return both\n",
    "\n",
    "\n",
    "def castable_to_int(obj):\n",
    "    \"\"\"Return True if obj is castable to int, False otherwise.\"\"\"\n",
    "    try:\n",
    "        int(obj)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def cast_to_int(df, colname):\n",
    "    \"\"\"Cast df[colname] to dtype int. All rows that are not castable\n",
    "    to int are dropped. df is partially modified in place, but the return\n",
    "    value should be used.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = df.astype({colname: np.int_}, copy=False)\n",
    "    except ValueError:\n",
    "        castable_rows = df[colname].apply(castable_to_int)\n",
    "        df = df[castable_rows]\n",
    "        df = df.astype({colname: np.int_}, copy=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# events_by_station is the DataFrame we are constructing. First check if it's already\n",
    "# on disk.\n",
    "events_by_station_path = Path(\"./events_by_station.p\")\n",
    "if events_by_station_path.exists():\n",
    "    events_by_station = pd.read_pickle(events_by_station_path)\n",
    "else:\n",
    "    # Collect the paths to all the CSV files.\n",
    "    datafiles = sorted(os.listdir(bikefolder))\n",
    "    folderpath = Path(bikefolder)\n",
    "    datapaths = [folderpath / Path(file) for file in datafiles]\n",
    "    datapaths = [p for p in datapaths if p.suffix == \".csv\"]\n",
    "\n",
    "    # Initialize a dictionary that will have as keys station ID numbers, and as values\n",
    "    # sets that include all the names this station has had in the files.\n",
    "    station_allnames = {}\n",
    "\n",
    "    # Each CSV file will list events in some time window. We process them one-by-one,\n",
    "    # collect all the DataFrames for individual time windows to `pieces`, and concatenate\n",
    "    # them at the end.\n",
    "    pieces = []\n",
    "    # Columns of the CSV files that we need.\n",
    "    cols = [\n",
    "        \"Duration\",\n",
    "        \"End Date\",\n",
    "        \"EndStation Id\",\n",
    "        \"EndStation Name\",\n",
    "        \"Start Date\",\n",
    "        \"StartStation Id\",\n",
    "        \"StartStation Name\",\n",
    "    ]\n",
    "    # At least one CSV file gives us trouble because it doesn't list station IDs, only station\n",
    "    # names. We'll collect the paths to those CSV files to `problem_paths` and deal with them\n",
    "    # at the end.\n",
    "    problem_paths = []\n",
    "    for path in datapaths:\n",
    "        print(\"Processing {}\".format(path))\n",
    "        try:\n",
    "            df = pd.read_csv(path, usecols=cols, encoding=\"ISO-8859-2\")\n",
    "        except ValueError as e:\n",
    "            # Some files have missing or abnormaly named columns. We'll deal with them later.\n",
    "            problem_paths.append(path)\n",
    "            continue\n",
    "        # Drop any rows that have missing values.\n",
    "        df = df[~df.isna().any(axis=1)]\n",
    "        # Drop any anomalously short trips. Probably somebody just taking a bike and putting\n",
    "        # it right back in. Durations are in seconds.\n",
    "        df = df[df[\"Duration\"] > 60]\n",
    "        # Cast the columns to the right types. This is easier ones NAs have been dropped.\n",
    "        df = cast_to_int(df, \"EndStation Id\")\n",
    "        df = cast_to_int(df, \"StartStation Id\")\n",
    "        # Turn the date columns from strings into datetime objects rounded to the hour.\n",
    "        df = clean_datetime_column(df, \"End Date\")\n",
    "        df = clean_datetime_column(df, \"Start Date\")\n",
    "        events = compute_both_events(df)\n",
    "        pieces.append(events)\n",
    "\n",
    "        # Add station names appearing in this file to our collection of names.\n",
    "        add_station_names(\n",
    "            station_allnames, df, \"EndStation Name\", \"EndStation Id\"\n",
    "        )\n",
    "        add_station_names(\n",
    "            station_allnames, df, \"StartStation Name\", \"StartStation Id\"\n",
    "        )\n",
    "\n",
    "    # Now that we've collected all the different names that the same station goes by,\n",
    "    # we'll pick one of them to be the name we'll use. We do this by just picking the\n",
    "    # one that is alphabetically first. We'll also make a dictionary that goes the other\n",
    "    # way around, for each name it gives the corresponding station ID.\n",
    "    station_ids = {}\n",
    "    station_names = {}\n",
    "    for k, v in station_allnames.items():\n",
    "        v = sorted(v)\n",
    "        station_names[k] = v[0]\n",
    "        for name in v:\n",
    "            station_ids[name] = k\n",
    "\n",
    "    def get_station_id(name):\n",
    "        try:\n",
    "            return station_ids[name]\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "\n",
    "    # Let's deal with the problem cases. They are ones that are missing station ID columns.\n",
    "    # They do have the station names though, so we'll use those to, with the above dictionary\n",
    "    # to get the IDs.\n",
    "    print(\"Doing the problem cases ({} of them).\".format(len(problem_paths)))\n",
    "    safe_cols = [\n",
    "        \"Duration\",\n",
    "        \"End Date\",\n",
    "        \"EndStation Name\",\n",
    "        \"Start Date\",\n",
    "        \"StartStation Name\",\n",
    "    ]\n",
    "    for path in problem_paths:\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, usecols=safe_cols, encoding=\"ISO-8859-2\")\n",
    "        # Drop any rows that have missing values.\n",
    "        df = df[~df.isna().any(axis=1)]\n",
    "        # Drop any anomalously short trips. Probably somebody just taking a bike and putting\n",
    "        # it right back in.\n",
    "        df = df[df[\"Duration\"] > 60]\n",
    "        # Add a column of station IDs, based on names.\n",
    "        df[\"EndStation Id\"] = df[\"EndStation Name\"].apply(get_station_id)\n",
    "        df[\"StartStation Id\"] = df[\"StartStation Name\"].apply(get_station_id)\n",
    "        # Turn the date columns from strings into datetime objects rounded to the hour.\n",
    "        clean_datetime_column(df, \"End Date\")\n",
    "        clean_datetime_column(df, \"Start Date\")\n",
    "        events = compute_both_events(df)\n",
    "        pieces.append(events)\n",
    "\n",
    "    # Finally, concatenate all the data we've accumulated into a single DataFrame.\n",
    "    events_by_station = pd.concat(pieces).fillna(0.0)\n",
    "    # Several files may have contained entries for the same hour, which means that\n",
    "    # events_by_station has duplicate entries in the index. Get rid of them by summing.\n",
    "    events_by_station = events_by_station.groupby(\"Date\").sum().sort_index()\n",
    "    # Finally rename the columns according to the chosen names for stations.\n",
    "    events_by_station = events_by_station.rename(\n",
    "        mapper=station_names, axis=1, level=0\n",
    "    )\n",
    "\n",
    "    # Store the file on disk so we can read it later.\n",
    "    events_by_station.to_pickle(events_by_station_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's most of the processing done, but there's still a few nonsense stations in the data, used for testing purposes and so. Here's a handy way to find them: For each station, take the maximum number of events it has had in one hour, and divide that by the average number of events for the same station. This yields a high number for stations that have very peaked usage profiles, like these short-lived test stations do. Print some of the top stations by this metric to find their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "Electrical Workshop PS                                      1757.661290\n",
       "PENTON STREET COMMS TEST TERMINAL _ CONTACT MATT McNULTY    1615.675676\n",
       "tabletop1                                                   1066.166667\n",
       "Contact Centre, Southbury House                              785.873684\n",
       "6                                                            569.021661\n",
       "Pop Up Dock 1                                                567.806009\n",
       "Mechanical Workshop Penton                                   223.889301\n",
       "South Quay East, Canary Wharf                                133.832111\n",
       "Westfield Eastern Access Road, Shepherd's Bush                88.865062\n",
       "Thornfield House, Poplar                                      83.626863\n",
       "Fore Street Avenue: Guildhall                                 72.077569\n",
       "Upper Grosvenor Street, Mayfair                               71.536004\n",
       "Courland Grove , Wandsworth Road                              57.572555\n",
       "Manfred Road, East Putney                                     54.716094\n",
       "Aberfeldy Street, Poplar                                      54.258897\n",
       "Castalia Square :Cubitt Town                                  53.326767\n",
       "Stebondale Street, Cubitt Town                                53.173161\n",
       "Grant Road Central, Clapham Junction                          53.160678\n",
       "Here East South, Queen Elizabeth Olympic Park                 52.018072\n",
       "Teviot Street, Poplar                                         47.432214\n",
       "Stewart's Road, Nine Elms                                     47.168675\n",
       "Abbotsbury Road, Holland Park                                 46.499915\n",
       "Clarkson Street :Bethnal Green                                46.496873\n",
       "Malmesbury Road :Bow                                          45.607424\n",
       "Here East North, Queen Elizabeth Olympic Park                 45.450386\n",
       "Bevington Road, North Kensington                              45.329752\n",
       "Cantrell Road, Bow                                            45.218407\n",
       "Lord's, St. John's Wood                                       44.333229\n",
       "Birkenhead Street, King's Cross                               43.918274\n",
       "Knightsbridge, Hyde Park                                      43.819764\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_within_window(s):\n",
    "    starttime = s.ne(0).idxmax()\n",
    "    endtime = s[::-1].ne(0).idxmax()\n",
    "    return s[starttime:endtime].mean()\n",
    "\n",
    "\n",
    "a = events_by_station.sum(axis=1, level=0)\n",
    "(a.max() / a.aggregate(mean_within_window)).sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just drop the weird ones. No, I won't contact Matt McNulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "improper_stations = [\n",
    "    \"Electrical Workshop PS\",\n",
    "    \"PENTON STREET COMMS TEST TERMINAL _ CONTACT MATT McNULTY\",\n",
    "    \"tabletop1\",\n",
    "    \"Pop Up Dock 1\",\n",
    "    \"6\",\n",
    "    \"Mechanical Workshop Penton\",\n",
    "]\n",
    "events_by_station = events_by_station.drop(improper_stations, axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 02:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16 22:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 00:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47043 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     End  Start  End  Start\n",
       "Date                                       \n",
       "2012-01-04 00:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 01:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 02:00:00  2.0    0.0  0.0    0.0\n",
       "2012-01-04 03:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 04:00:00  0.0    0.0  0.0    0.0\n",
       "...                  ...    ...  ...    ...\n",
       "2017-05-16 22:00:00  1.0    1.0  0.0    0.0\n",
       "2017-05-16 23:00:00  0.0    0.0  0.0    0.0\n",
       "2017-05-17 00:00:00  1.0    0.0  0.0    0.0\n",
       "2017-05-17 01:00:00  0.0    0.0  0.0    0.0\n",
       "2017-05-17 02:00:00  0.0    0.0  0.0    0.0\n",
       "\n",
       "[47043 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO What is up with this?\n",
    "events_by_station[\"Exhibition Road Museums, Knightsbridge\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data set cleaned, let's explore it a bit before starting our main task of prediction. I pick a few stations as examples, and plot their usage profile, first over the hours of a week, averaged over all weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = events_by_station.index.to_series()\n",
    "example_stations = [\n",
    "    \"Waterloo Station 3, Waterloo\",\n",
    "    \"Hyde Park Corner, Hyde Park\",\n",
    "    \"Wenlock Road , Hoxton\",\n",
    "    \"Stonecutter Street, Holborn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8658fd896d944dd196851d325b996722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Give the plots widths from variance or something like [25%, 75%] limits (what are these called again?).\n",
    "example_means_over_week = (\n",
    "    events_by_station[example_stations]\n",
    "    .groupby([times.dt.weekday, times.dt.hour])\n",
    "    .mean()\n",
    ")\n",
    "# Format the DataFrame into a format that seaborn likes.\n",
    "example_means_over_week.index.rename([\"Day\", \"Hour\"], inplace=True)\n",
    "example_means_over_week = (\n",
    "    example_means_over_week.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_3\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "example_means_over_week[\"Weekday\"] = example_means_over_week.apply(\n",
    "    lambda x: x[\"Day\"] + x[\"Hour\"] / 24, axis=1,\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    example_means_over_week,\n",
    "    col_wrap=1,\n",
    "    aspect=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Weekday\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The week starts from Monday in this plot.\n",
    "\n",
    "The example stations here we deliberately picked to show different kinds of trends. Stonecutter Street and Waterloo are clearly commuter stations, that see action in the morning and the afternoon on weekdays. One is the end point of commuting trips, the other the start. Hyde Park Corner is very different, with popularity peaks being in the afternoon, and especially weekend afternoons. Wenlock Road is a bitter of mixture of these features, gets much less traffic overall.\n",
    "\n",
    "Let's do the same thing over a year instead of a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f52129eeaa44cf0b375b585aa6c860a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Give the plots widths from variance or something like [25%, 75%] limits (what are these called again?).\n",
    "example_means_over_year = (\n",
    "    events_by_station[example_stations].groupby(times.dt.week).mean()\n",
    ")\n",
    "# Leave out the first and last weeks, since they are usually shorter and thus the data isn't comparable.\n",
    "example_means_over_year = example_means_over_year.iloc[1:51]\n",
    "# Format to what seaborn likes.\n",
    "example_means_over_year.index.rename(\"Week\", inplace=True)\n",
    "example_means_over_year = (\n",
    "    example_means_over_year.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    example_means_over_year,\n",
    "    col_wrap=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Week\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, different profiles, with Waterloo and Stonecutter, the commuter stations, being more even over the year (note different vertical scales), and Hyde Park Corner showing a huge preference for summer cycling.\n",
    "\n",
    "Finally, in addition to weekly and seasonal trends, the stations have different long term trends. Here are the yearly rolling averages over our whole data period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40a18ac32f74f59a07e9459a23e4722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yearly_rolling = (\n",
    "    events_by_station.loc[:, example_stations]\n",
    "    .rolling(\"365d\", min_periods=24 * 90)\n",
    "    .mean()\n",
    ")\n",
    "yearly_rolling = (\n",
    "    yearly_rolling.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    yearly_rolling,\n",
    "    col_wrap=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Date\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rising and falling trends, and for some reason a period of time when people stopped arriving at Waterloo Station with their Boris Bikes, but didn't stop departing from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of the above exploratory plots was to get a feel for the kind of trends we can expect to see, and to illustrate the differences between stations. Now that we start doing modelling and prediction, we'll always fit all our models per station and event type. I call a pair like (\"Waterloo Station 3, Waterloo\", \"Start\") a column, and so we'll be fitting to each column separately. We'll use some of the above example columns as our validation set.\n",
    "\n",
    "Before we start doing predictions, we should decide on how success is measured, and set up a framework for measuring performance of models. I choose to use a type of cross-validation often done with time series data, sometimes known as rolling cross-validation. In it you divide the data into consecutive chunks, each of which acts as a test set. For each test set, you train the model on all the data you have from before that test set. This is like the usual kind of cross-validation, except we never train on data from the future of the test set, to not accidentally create wormholes and disrupt the spacetime by having effects from the future affect our prediction.\n",
    "\n",
    "To have the validation run in a reasonable time, I choose to predict half a year at a time, and only start predictions after two years of data has been accumulated, because otherwise there isn't much to train on.\n",
    "\n",
    "Finally, we need to decide on an error metric. I choose to use the mean absolute error, aka MAE. Why MAE, and not mean squared error, MSE? Because a bike is a bike is a bike. If we predict that there will be 10 departures, and there are in fact 20, causing an error of 10 bikes, this is only 10 times worse than if we had predicted 19 and made an error of 1 bike. With MSE, this would be treated as being a 100 times worse, which just isn't fair: Imagining a case where our predicting model is used for deciding how many bikes should be kept at each station, one missing bike means one unhappy person, ten means ten, not a hundred. This is especially important when comparing predictions between different stations, some of which see much more trafic than others.\n",
    "\n",
    "Below is a class that implements the above type of cross-validation. There's one class that does this for a single column of data, and another that uses the first one to do multiple columns at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingValidatorSingleColumn:\n",
    "    \"\"\"A class for doing rolling cross-validation for data from a single column.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data, predictors, min_training_time, prediction_time,\n",
    "    ):\n",
    "        # Each validator keeps a dictionary of all the modelclasses it has tested, and the\n",
    "        # results that it got.\n",
    "        self.models = {}\n",
    "        # A cv_batch is a cross-validation batch, consisting of a set of training data,\n",
    "        # training predictors, test data, and test predictors. We slice up the data given\n",
    "        # to as many batches as we can, given the size of the test sets we want, and the\n",
    "        # minimum amount of data we need for training set to make sense. We start the slicing\n",
    "        # from the end, so even the shortest training set may be longer than the minimum\n",
    "        # required.\n",
    "        self.cv_batches = []\n",
    "        first_time = data.index.min()\n",
    "        last_time = data.index.max()\n",
    "        test_end_time = last_time\n",
    "        cutoff = test_end_time - prediction_time\n",
    "        while cutoff > first_time + min_training_time:\n",
    "            training_data = data[:cutoff]\n",
    "            training_predictors = predictors[:cutoff]\n",
    "            test_data = data[cutoff:test_end_time]\n",
    "            test_predictors = predictors[cutoff:test_end_time]\n",
    "            self.cv_batches.append(\n",
    "                (\n",
    "                    training_data,\n",
    "                    training_predictors,\n",
    "                    test_data,\n",
    "                    test_predictors,\n",
    "                )\n",
    "            )\n",
    "            test_end_time = cutoff\n",
    "            cutoff = test_end_time - prediction_time\n",
    "        msg = \"Created a RollingValidator with {} cross-validation batches.\".format(\n",
    "            len(self.cv_batches)\n",
    "        )\n",
    "        print(msg)\n",
    "\n",
    "    def test_modelclass(self, modelclass, print_progress=False):\n",
    "        \"\"\"Test a given modelclass with this RollingValidator. A modelclass should be class\n",
    "        the instances of which have the methods `train` and `predict`. `train` in training data\n",
    "        and training predictors, and predict takes in predictors and returns predictions.\n",
    "        \n",
    "        A separate instance of the model class is created for each cross-validation batch,\n",
    "        trained and asked to predict on the test set. It is also asked to predict on the \n",
    "        training set. Errors are computed for both. All predictions and errors are stored\n",
    "        in self.models[modelclass.classname]. The method returns the MAE over all the\n",
    "        cross-validation batches.\n",
    "        \"\"\"\n",
    "        # We collect the predictions and errors from different batches.\n",
    "        test_errors = []\n",
    "        training_errors = []\n",
    "        test_predictions = []\n",
    "        training_predictions = []\n",
    "        for (i, cv_batch,) in enumerate(self.cv_batches):\n",
    "            (\n",
    "                training_data,\n",
    "                training_predictors,\n",
    "                test_data,\n",
    "                test_predictors,\n",
    "            ) = cv_batch\n",
    "            if print_progress:\n",
    "                print(\"Training for batch {}.\".format(i))\n",
    "            model = modelclass()\n",
    "            model.train(\n",
    "                training_data, training_predictors,\n",
    "            )\n",
    "            if print_progress:\n",
    "                print(\"Predicting for batch {}.\".format(i))\n",
    "            test_prediction = model.predict(test_predictors)\n",
    "            training_prediction = model.predict(training_predictors)\n",
    "            test_error = test_prediction - test_data\n",
    "            training_error = training_prediction - training_data\n",
    "            test_errors.append(test_error)\n",
    "            training_errors.append(training_error)\n",
    "            test_predictions.append(test_prediction)\n",
    "            training_predictions.append(training_prediction)\n",
    "        test_mae = pd.concat(test_errors).abs().mean()\n",
    "        training_mae = pd.concat(training_errors).abs().mean()\n",
    "        self.models[modelclass.classname] = {\n",
    "            \"test_mae\": test_mae,\n",
    "            \"training_mae\": training_mae,\n",
    "            \"test_errors\": test_errors,\n",
    "            \"training_errors\": training_errors,\n",
    "            \"test_predictions\": test_predictions,\n",
    "            \"training_predictions\": training_predictions,\n",
    "        }\n",
    "        return test_mae\n",
    "\n",
    "\n",
    "class RollingValidator:\n",
    "    \"\"\"A class for doing rolling cross-validation for data from a multiple columns.\n",
    "    Each column is run individually, using RollingValidatorSingleColumn.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        common_predictors,\n",
    "        specific_predictors,\n",
    "        min_training_time,\n",
    "        prediction_time,\n",
    "    ):\n",
    "        \"\"\"Initialization of a multicolumn RollingValidator takes, in addition\n",
    "        to data to fit to and predictors common to all stations, also an argument\n",
    "        called `specific_predictors`. This one should be a dictionary or DataFrame\n",
    "        with one entry/column for each column in data, that holds predictors specific\n",
    "        to that column only. It can also be None, in which case only the common\n",
    "        predictors are used.\"\"\"\n",
    "        self.models = {}\n",
    "        self.subrvs = {}\n",
    "        # Create a RollingValidatorSingleColumn for each column in data.\n",
    "        for c in data.columns:\n",
    "            data_c = pd.DataFrame(data[c])\n",
    "            if specific_predictors is not None and c in specific_predictors:\n",
    "                predictors_c = pd.concat(\n",
    "                    [common_predictors, specific_predictors[c]], axis=1\n",
    "                )\n",
    "            else:\n",
    "                predictors_c = common_predictors\n",
    "            subrv = RollingValidatorSingleColumn(\n",
    "                data_c, predictors_c, min_training_time, prediction_time\n",
    "            )\n",
    "            self.subrvs[c] = subrv\n",
    "\n",
    "    def test_modelclass(self, modelclass, print_progress=False):\n",
    "        \"\"\"Test a given modelclass with this RollingValidator. This runs\n",
    "        RollingValidatorSingleColumn.test_modelclass for each column individually,\n",
    "        and collects the result to a single dictionary self.models. It returns\n",
    "        the sum of the MAEs for each column.\n",
    "        \"\"\"\n",
    "        for c, subrv in self.subrvs.items():\n",
    "            if print_progress:\n",
    "                print(\"Running RV on {}.\".format(c))\n",
    "            subrv.test_modelclass(modelclass, print_progress=print_progress)\n",
    "        # Collect the results into DataFrames that have different columns for the\n",
    "        # different columns in the original data.\n",
    "        classname = modelclass.classname\n",
    "        self.models[classname] = {}\n",
    "        for k in (\"test_mae\", \"training_mae\"):\n",
    "            self.models[classname][k] = pd.concat(\n",
    "                [subrv.models[classname][k] for subrv in self.subrvs.values()]\n",
    "            )\n",
    "        # The next(iter( part just takes the first of the entries in .values().\n",
    "        num_batches = len(next(iter(self.subrvs.values())).cv_batches)\n",
    "        for k in (\n",
    "            \"test_errors\",\n",
    "            \"training_errors\",\n",
    "            \"test_predictions\",\n",
    "            \"training_predictions\",\n",
    "        ):\n",
    "            self.models[classname][k] = [\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        subrv.models[classname][k][i]\n",
    "                        for subrv in self.subrvs.values()\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "                for i in range(num_batches)\n",
    "            ]\n",
    "        test_mae = self.models[classname][\"test_mae\"].sum()\n",
    "        return test_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a framework for cross-validating, and we know what we want to predict, what should we give our models as predictors? There are at least two kinds of predictors we could use: Seasonal and autoregressive. By seasonal I mean things like which weekday is it, and what time it is. By autoregressive I mean past values in the same column.\n",
    "\n",
    "Let's talk about seasonal ones first. As we saw above, there are strong variations in bike usage by the hour and weekday, and some clear variation also over the year. We could encode this is several different ways. The weekdays, especially weekend vs Monday to Friday, are clearly very distinct, and since there aren't two many of them either, dummy encoding seems like a good idea: 7 predictor variables that are 1 or 0 depending on whether it's that day of the week or not. For the intraday and intrayear patterns, I try two different encodings, dummy encoding and trigonometric. In the first one, each hour of the day and each month of the year gets it's own dummy variable. We could also consider doing dummies for weeks of the year instead of months, but let's try to avoid getting a huge number of predictor variables, for performance reasons if not otherwise. For the trigonometric encoding I turn the hours of the day and weeks of a year into angles around a circle, and then create two predictor variables, the sine and the cosine of that angle. They create a simple but natural encoding of continuous cyclical variables, and combined together they don't favor any one part of the cycle over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all the dummy encoded predictors.\n",
    "weekday_dummies = pd.get_dummies(times.dt.weekday_name)\n",
    "month_dummies = pd.get_dummies(times.dt.month)\n",
    "hour_dummies = pd.get_dummies(times.dt.hour)\n",
    "hour_dummies = hour_dummies.rename(\n",
    "    columns={c: \"Hour {}\".format(c) for c in hour_dummies.columns}\n",
    ")\n",
    "month_dummies = month_dummies.rename(\n",
    "    columns={c: \"Month {}\".format(c) for c in month_dummies.columns}\n",
    ")\n",
    "predictors_dum = pd.concat(\n",
    "    [month_dummies, hour_dummies, weekday_dummies,], axis=1,\n",
    ")\n",
    "\n",
    "# Create a DataFrame with weekdays dummy encoded, but weeks and hours\n",
    "# trigonometricly encoded.\n",
    "day_angles = 2 * np.pi * times.dt.hour / 24\n",
    "day_trigonometrics = pd.DataFrame(\n",
    "    {\"Day sine\": np.sin(day_angles), \"Day cosine\": np.cos(day_angles)}\n",
    ")\n",
    "year_angles = 2 * np.pi * times.dt.week / 52\n",
    "year_trigonometrics = pd.DataFrame(\n",
    "    {\"Year sine\": np.sin(year_angles), \"Year cosine\": np.cos(year_angles),}\n",
    ")\n",
    "predictors_trig = pd.concat(\n",
    "    [weekday_dummies, day_trigonometrics, year_trigonometrics], axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are tasked to be the human model predicting bike use. You've learned that for a given station, one Mondays in January at 9am you usually get around 50 people departing. But now for the past three weeks straight, you've seen much less customers than usually. You should probably adjust your estimates then.\n",
    "\n",
    "This gets to the autoregressive features. You could come up with any number of these: a weekly rolling average, monthly rolling average, usage at the same time of the day for three previous days, etc. We shouldn't include everything though, to avoid overfitting. What I've found works quite well, is to simple give as a predictor the value from the same column exactly a week before. The intraweek patterns are the strongest, fastest moving patterns in the data, and also very reliable, and looking at the usage from exactly a week ago gives pretty good idea of what to expect this time. The only downside is that we have to discard the first week of data since we don't have preceding data for that, but we've got hundreds of weeks left still.\n",
    "\n",
    "Finally, there are more than a thousand columns in our data, and I don't have the patience to run the every model on all of them just to test it. We'll pick three example columns as our validation set of columns, that represent different types of stations as seen in the above extrapolation plots: Waterloo to represent commuter-heavy stations, Hyde Park to represent leisure rides, and Wenlock Road to represent a quieter station with a mix of users. This also gives us a natural way to separate validation from testing: We'll do model selecting using these three columns, and then at the very end test performance using a different set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from exactly a week before.\n",
    "events_offset = events_by_station.shift(freq=pd.Timedelta(\"7d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard the first week, so that all our predictors and data cover the same\n",
    "# timespan.\n",
    "first_time = events_offset.index.min()\n",
    "last_time = events_by_station.index.max()\n",
    "data = events_by_station.loc[first_time:last_time, :]\n",
    "predictors_trig = predictors_trig.loc[first_time:last_time, :]\n",
    "predictors_dum = predictors_dum.loc[first_time:last_time, :]\n",
    "events_offset = events_offset.loc[first_time:last_time, :]\n",
    "times = data.index.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\n",
    "    (\"Waterloo Station 3, Waterloo\", \"Start\"),\n",
    "    (\"Hyde Park Corner, Hyde Park\", \"End\"),\n",
    "    (\"Wenlock Road , Hoxton\", \"End\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n"
     ]
    }
   ],
   "source": [
    "specific_predictors = events_offset[test_columns]\n",
    "min_training_time = 2 * pd.Timedelta(\"365d\")\n",
    "prediction_time = 0.5 * pd.Timedelta(\"365d\")\n",
    "rv_trig = RollingValidator(\n",
    "    data[test_columns],\n",
    "    predictors_trig,\n",
    "    specific_predictors,\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")\n",
    "rv_dum = RollingValidator(\n",
    "    data[test_columns],\n",
    "    predictors_dum,\n",
    "    specific_predictors,\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "# dbg_timerange = slice(\"2017-01-01\", None)\n",
    "# min_training_time = 2 * pd.Timedelta(\"30d\")\n",
    "# prediction_time = 0.5 * pd.Timedelta(\"30d\")\n",
    "# rv_trig = RollingValidator(\n",
    "#     data[dbg_timerange],\n",
    "#     predictors_trig[dbg_timerange],\n",
    "#     specific_predictors[dbg_timerange],\n",
    "#     min_training_time,\n",
    "#     prediction_time,\n",
    "# )\n",
    "# rv_dum = RollingValidator(\n",
    "#     data[dbg_timerange],\n",
    "#     predictors_dum[dbg_timerange],\n",
    "#     specific_predictors[dbg_timerange],\n",
    "#     min_training_time,\n",
    "#     prediction_time,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With validation set up, time to make our first models. To set a baseline, here two very simple ones: `SimpleMean` just takes the mean of all the event counts in the column in question, and predicts that usage at all times will just be the mean value. `LastWeek` always predicts that usage now will be exactly the same as a week ago. We run our RollingValidator on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMean:\n",
    "    classname = \"SimpleMean\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, data, predictors):\n",
    "        mean = pd.DataFrame(data.mean())\n",
    "        self.model = mean\n",
    "\n",
    "    def predict(self, predictors):\n",
    "        mean = self.model\n",
    "        index = predictors.index\n",
    "        predictions = mean.T.apply(lambda x: [x[0]] * len(index)).set_index(\n",
    "            index\n",
    "        )\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastWeek:\n",
    "    classname = \"LastWeek\"\n",
    "\n",
    "    def train(self, data, predictors):\n",
    "        pass\n",
    "\n",
    "    def predict(self, predictors):\n",
    "        # TODO Fix relying on column order\n",
    "        predictions = pd.DataFrame(predictors.iloc[:, -1])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMean\n",
      "MAE: 25.581\n",
      "LastWeek\n",
      "MAE: 12.239\n"
     ]
    }
   ],
   "source": [
    "for modelclass in [SimpleMean, LastWeek]:\n",
    "    print(modelclass.classname)\n",
    "    err = rv_trig.test_modelclass(modelclass)\n",
    "    print(\"MAE: {:.3f}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives an idea of what we can hope for. If we get a MAE of more than 25 means that something's going badly wrong. If we are above 12 or so, we aren't doing anything especially smart, a simple same-as-last-week prediction is just as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers easy-to-use classes for a lot of different kinds of regression models, and they are wonderfully easy to swap between, so let's make use of that. Here's a class that can be subclassed to run practically any scikit-learn regressor.\n",
    "\n",
    "Note here that we should think about data normalization a bit. Most of our predictors come normalized already: They are dummy variables, or sinusoidal functions in the range [-1,+1]. But the data from a week before does not, and this is an issue for some regressors. Below we normalize this predictor variable by just dividing by the standard deviation. It brings it into a range comparable with the other predictors, without losing the property that the data is inherently non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericModel:\n",
    "    # Place-holders for subclasses to replace.\n",
    "    # Regressor should be a function that returns a scikit-learn regressor.\n",
    "    # classname is a string to be used as a key when referring to this class.\n",
    "    regressor = None\n",
    "    classname = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.column_name = None\n",
    "        self.stds = {}\n",
    "\n",
    "    def _normalize_predictors_train(self, predictors):\n",
    "        \"\"\"Normalize given predictors. predictors shoud be a dataframe, and every column\n",
    "        that has \"Start\" or \"End\" in the name will be divided by its standard deviation.\n",
    "        This function is meant to be called before training the model, and we store the\n",
    "        standard deviations, so that the same normalization can be applied to when doing\n",
    "        prediction.\n",
    "        \"\"\"\n",
    "        predictors = predictors.copy()\n",
    "        self.stds = {}\n",
    "        for c in predictors.columns:\n",
    "            try:\n",
    "                is_stationcolumn = \"Start\" in c or \"End\" in c\n",
    "            except TypeError:\n",
    "                is_stationcolumn = False\n",
    "            if is_stationcolumn:\n",
    "                col = predictors[c]\n",
    "                std = col.std()\n",
    "                predictors[c] = col / std\n",
    "                self.stds[c] = std\n",
    "        return predictors\n",
    "\n",
    "    def _normalize_predictors_predict(self, predictors):\n",
    "        \"\"\"Normalize the given predictors the same way they were normalized before training.\n",
    "        Meant to be called before predicting.\n",
    "        \"\"\"\n",
    "        predictors = predictors.copy()\n",
    "        for c in predictors.columns:\n",
    "            try:\n",
    "                is_stationcolumn = \"Start\" in c or \"End\" in c\n",
    "            except TypeError:\n",
    "                is_stationcolumn = False\n",
    "            if is_stationcolumn:\n",
    "                col = predictors[c]\n",
    "                std = self.stds[c]\n",
    "                predictors[c] = col / std\n",
    "        return predictors\n",
    "\n",
    "    def train(self, data, predictors):\n",
    "        predictors = self._normalize_predictors_train(predictors)\n",
    "        model = self.regressor()\n",
    "        model.fit(predictors, data)\n",
    "        self.model = model\n",
    "        self.column_name = data.columns[0]\n",
    "\n",
    "    def predict(self, predictors):\n",
    "        predictors = self._normalize_predictors_predict(predictors)\n",
    "        predictions = self.model.predict(predictors)\n",
    "        name = self.column_name\n",
    "        index = predictors.index\n",
    "        predictions = np.squeeze(predictions)\n",
    "        predictions = pd.DataFrame({name: predictions}, index=index)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above, we construct a number of model classes using different regressors scikit-learn offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(GenericModel):\n",
    "    classname = \"Linear\"\n",
    "    regressor = linear_model.Ridge\n",
    "\n",
    "\n",
    "class KNeighbors(GenericModel):\n",
    "    classname = \"KNeighbors\"\n",
    "    regressor = lambda x: neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=5, weights=\"distance\"\n",
    "    )\n",
    "\n",
    "\n",
    "class LinearSVR(GenericModel):\n",
    "    classname = \"LinearSVR\"\n",
    "    regressor = lambda x: svm.LinearSVR(max_iter=5000)\n",
    "\n",
    "\n",
    "class RbfSVR(GenericModel):\n",
    "    classname = \"RbfSVR\"\n",
    "    regressor = lambda x: svm.SVR(kernel=\"rbf\", cache_size=500)\n",
    "\n",
    "\n",
    "class PolySVR(GenericModel):\n",
    "    classname = \"PolySVR\"\n",
    "    regressor = lambda x: svm.SVR(kernel=\"poly\", cache_size=500)\n",
    "\n",
    "\n",
    "class DecisionTree(GenericModel):\n",
    "    classname = \"DecisionTree\"\n",
    "    regressor = lambda x: tree.DecisionTreeRegressor(\n",
    "        criterion=\"mae\", max_depth=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularized linear model, k-nearest-neighbors with k=5, three support vector machines with different kernel functions, and a depth=3 decision tree. Why these? No strong reason, but I've been testing out different regressors and these all offer something different from the others conceptually, run on our data in a reasonable amount of time, and produce decent results. I am not an expert on any of these (on the contrary I actually hadn't used anything other than linear regression before this project), and I haven't done any systematic hyperparameter tuning, so it's well possible that better results could be found with some different model or choice of parameters. I'll go with these for now though.\n",
    "\n",
    "Here's a script that runs all the above models using both the trigonometric and the dummy encoding of our predictors. This takes a good while, on my laptop a few hours. Since the Jupyter kernel has a habit of crashing and we don't want to rerun this, I store the results in two files in the current working directory, one for each predictor encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMean\n",
      "trig mae: 25.581   (took 0.0 mins)\n",
      "dumm mae: 25.581   (took 0.0 mins)\n",
      "\n",
      "LastWeek\n",
      "trig mae: 12.239   (took 0.0 mins)\n",
      "dumm mae: 12.239   (took 0.0 mins)\n",
      "\n",
      "Linear\n",
      "trig mae: 12.502   (took 0.0 mins)\n",
      "dumm mae: 12.386   (took 0.0 mins)\n",
      "\n",
      "KNeighbors\n",
      "trig mae: 11.335   (took 0.2 mins)\n",
      "dumm mae: 11.547   (took 4.9 mins)\n",
      "\n",
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trig mae: 11.453   (took 0.1 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumm mae: 11.307   (took 0.1 mins)\n",
      "\n",
      "DecisionTree\n",
      "trig mae: 11.541   (took 5.6 mins)\n",
      "dumm mae: 11.688   (took 12.7 mins)\n",
      "\n",
      "RbfSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trig mae: 10.757   (took 16.8 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/markus/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-258816647fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_modelclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# We don't want to kill the whole script if something grows wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-6914f8ea4364>\u001b[0m in \u001b[0;36mtest_modelclass\u001b[0;34m(self, modelclass, print_progress)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running RV on {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0msubrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_modelclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Collect the results into DataFrames that have different columns for the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# different columns in the original data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-6914f8ea4364>\u001b[0m in \u001b[0;36mtest_modelclass\u001b[0;34m(self, modelclass, print_progress)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             model.train(\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_predictors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-4639fe738355>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, predictors)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_predictors_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    SimpleMean,\n",
    "    LastWeek,\n",
    "    Linear,\n",
    "    KNeighbors,\n",
    "    LinearSVR,\n",
    "    DecisionTree,\n",
    "    RbfSVR,\n",
    "    PolySVR,\n",
    "]\n",
    "for modelclass in classes:\n",
    "    print(modelclass.classname)\n",
    "    for rv, rv_name in (\n",
    "        (rv_trig, \"Trigonometric encoding\"),\n",
    "        (rv_dum, \"Dummy encoding\"),\n",
    "    ):\n",
    "        start = timer()\n",
    "        try:\n",
    "            err = rv.test_modelclass(modelclass)\n",
    "        except Exception as e:\n",
    "            # We don't want to kill the whole script if something grows wrong\n",
    "            # with one model, so just print the error and keep going.\n",
    "            print(e)\n",
    "        stop = timer()\n",
    "        time = (stop - start) / 60\n",
    "        print(\n",
    "            \"{}. MAE: {:.3f}   (took {:.1f} mins)\".format(rv_name, err, time)\n",
    "        )\n",
    "        with open(\"latest_rv_dum.p\", \"wb\") as f:\n",
    "            pickle.dump(rv_dum, f)\n",
    "        with open(\"latest_rv_trig.p\", \"wb\") as f:\n",
    "            pickle.dump(rv_trig, f)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need it, here's how you load the results from the disk if your kernel dies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"latest_rv_dum.p\", \"rb\") as f:\n",
    "    rv_dum = pickle.load(f)\n",
    "with open(\"latest_rv_trig.p\", \"rb\") as f:\n",
    "    rv_trig = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model does no better than our simple `LastWeek` thing, which isn't too surprising: For instance with the trigonometrically encoded variables, it can only ever fit sinusoidal patterns in the data. All the non-linear ones do better, but none by a huge margin. In fact, their performance is strikingly similar. k-nearest-neighbors, which is essentially just a more sophisticad version of just predicting past values reoccurring, improves over `LastWeek` by an average of one bike, linear SVR and our choice of decision tree do no better. The SVRs with non-linear kernels still improve a bit on this, but nothing drastic.\n",
    "\n",
    "The intuitive picture I draw from this is that beyond saying \"this week will be like last week\", there's only so much we can do to predict variations with the data we have. This little bit extra isn't too hard to get, different choices of regressors and encodings can do it, but beyond that, we are still left with an average error of a bit more than 10 bikes per hour, that nothing we've tried is able to get rid of. Of course, there will be a hard bottom for how well our models can do, given that there are random fluctuations and external driving forces we have no way of predicting (road closure/vandalism of a station/a big shop opens nearby/etc.). Perhaps we are getting pretty close to hitting that limit.\n",
    "\n",
    "To get a handle on how little or much our models may be overfitting, here are, in addition to the test set MAEs, also the training set ones, when using dummy encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Test     Training\n",
      "PoissonGLM                11.441   10.911\n",
      "SimpleMean                25.581   24.211\n",
      "LastWeek                  12.239   11.369\n",
      "Linear                    12.386   11.760\n",
      "KNeighbors                11.547   3.229\n",
      "LinearSVR                 11.307   10.486\n",
      "DecisionTree              11.688   10.693\n"
     ]
    }
   ],
   "source": [
    "print(\"{:25} Test     Training\".format(\"\"))\n",
    "for k, v in rv_dum.models.items():\n",
    "    test_mae = v[\"test_mae\"].sum()\n",
    "    training_mae = v[\"training_mae\"].sum()\n",
    "    print(\"{:25} {:.3f}   {:.3f}\".format(k, test_mae, training_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors of course does anomalously well since it's not really doing any fitting at all, but other than that, nothing too surprising or worrying here.\n",
    "\n",
    "Given that `LastWeek` already does almost as well as the fancier methods, one idea to try would be to apply all the above models to predicting differences in usage between now and a week ago, instead of predicting the usage directly. I tried this to some extent and found no great success. I suspect that when measuring variations instead of absolute values the yearly patterns for instance become quite hard to discern. Whatever the reason, it didn't work as well as I hoped.\n",
    "\n",
    "To get a more intuitive feel for how our above models too, let's see what the predictions from the winner of our above comparison, PolyRBF on trigonometricly encoded predictors, look like. Here's comparison between the predictions and the actual outcomes for the Hyde Park Corner station for one week in February 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVRpoly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a9db8d8f9281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot_columns = [(\"Wenlock Road , Hoxton\", \"End\")]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot_columns = [(\"Waterloo Station 3, Waterloo\",  \"Start\")]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodelclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVRpoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_errors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimewindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m pred = pd.concat(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVRpoly' is not defined"
     ]
    }
   ],
   "source": [
    "rv = rv_trig\n",
    "plot_column = (\"Hyde Park Corner, Hyde Park\", \"End\")\n",
    "timewindow = slice(\"2017-02-20\", \"2017-02-26\")\n",
    "# plot_columns = [(\"Wenlock Road , Hoxton\", \"End\")]\n",
    "# plot_columns = [(\"Waterloo Station 3, Waterloo\",  \"Start\")]\n",
    "modelclass = SVRpoly\n",
    "err = pd.concat(rv.models[modelclass.classname][\"test_errors\"]).sort_index()[\n",
    "    timewindow\n",
    "]\n",
    "pred = pd.concat(\n",
    "    rv.models[modelclass.classname][\"test_predictions\"]\n",
    ").sort_index()[timewindow]\n",
    "truth = pd.concat([l[3] for l in rv.cv_batches]).sort_index()[timewindow]\n",
    "plt.figure()\n",
    "plt.plot(truth[plot_column])\n",
    "plt.plot(pred[plot_column])\n",
    "plt.ylabel(plot_column[1])\n",
    "plt.title(plot_column[0])\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been using generic machine learning methods that can be applied to any regression problem. But there's more about the structure of our data that we know, and haven't used yet. At any given time and for any given bike station, there's a rate at which people are coming to the station to take or return bikes. Furthermore, there's no reason to assume that one person's arrival would affect when the next one comes (unless, maybe, the station gets overcrowded, but let's ignore that possiblity). This is exactly the kind of situation where the number of people arriving within a fixed time window should follow a Poisson distribution.\n",
    "\n",
    "A Poisson distribution is defined by a single number, the rate at which events occur. That means that if you specify the its mean λ, you've specified everything there is to know about the distribution. Now of course the rate at which events occur, and thus λ, varies over time, but this gives an idea for a different, more principled way of modelling our data: assume that the data is Poisson distribution, and try to fit a function that predicts its mean. This is called Poisson regression.\n",
    "\n",
    "More specifically, we assume that the data follows a Poisson distribution, and that the _logarithm of the mean depends linearly on our predictors_. In statistics vocabulary, this is a generalized linear model with a Poisson distribution and a logarithmic link function. You may ask why specifically have a log-linear model for the mean. One reason is that its simple and common enough choice that the fitting can be done with standard techniques that a good statistics package has implemented. Another is that due to how taking a logarithm turns multiplication into addition, what we are saying is that the mean should be a product of terms that depend on our predictors. This is more natural than saying it would be the sum (like what a linear regression model does), since for instance seasonal variation will more likely increase or decrease bike usage by a fixed percentage, rather than a fix number of bikes.\n",
    "\n",
    "The Python package statsmodels has some neat classes and methods of doing exactly this kind of Poisson regression. The optimization is implemented as a likelihood maximization. Here's a model class that uses statmodels Poisson regression, and can be fed to our cross-validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonGLM:\n",
    "    classname = \"PoissonGLM\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.column_name = None\n",
    "\n",
    "    def train(self, data, predictors):\n",
    "        glm_poisson = sm.GLM(data, predictors, family=sm.families.Poisson())\n",
    "        model = glm_poisson.fit()\n",
    "        self.model = model\n",
    "        self.column_name = data.columns[0]\n",
    "\n",
    "    def predict(self, predictors):\n",
    "        name = self.column_name\n",
    "        times = predictors.index.to_series()\n",
    "        model = self.model\n",
    "        predictions = model.predict(predictors)\n",
    "        predictions = pd.DataFrame({name: predictions}, index=times)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it performs. Due to the multiplicative nature of the log-linear nature, dummy variables are a much more natural encoding hear than trigonometric functions, so I'll go with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonGLM\n",
      "MAE: 11.441\n"
     ]
    }
   ],
   "source": [
    "print(PoissonGLM.classname)\n",
    "err = rv_dum.test_modelclass(PoissonGLM)\n",
    "print(\"MAE: {:.3f}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's as good as many of the non-linear ML methods, and just a little bit worse than the best of them, the non-linear SVRs. Poisson regression is much faster though (SVRs have a time complexity that scales as the square of the number of samples, I think Poisson regression is linear, but don't quote me on that), and most importantly much more interpretable. I'll be sticking with Poisson from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One natural candidate for explaining some of the remaining variation that our model fails to capture is weather. Presumably a cold downpour would decrease the number of cyclists, and nice and sunny would increase it. Luckily, we have weather data for London at our disposal, so we can check whether that's true.\n",
    "\n",
    "First let's load the weather data from a file, which has been downloaded from the [NOAA](https://www.ncdc.noaa.gov/cdo-web/search) website and is inlucded in the git repo. It has plenty of columns for minimum and maximum temperatures, snow depths (yeah, right) and whatnot, but many of them have more data missing than present. However, two are well-covered: Precipitation and daily average temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = pd.read_csv(\n",
    "    \"./data/weather/london_weather_data.csv\",\n",
    "    usecols=[\"DATE\", \"PRCP\", \"TAVG\"],\n",
    "    encoding=\"ISO-8859-2\",\n",
    ")\n",
    "wdf[\"DATE\"] = pd.to_datetime(wdf[\"DATE\"])\n",
    "wdf = wdf.set_index(\"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict the data to our chosen time window, and fill the 6 missing precipitation data points as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = wdf[first_time:last_time]\n",
    "# There's only 6 NaNs in this time range, so how we fill them doesn't really matter much.\n",
    "wdf[\"PRCP\"] = wdf[\"PRCP\"].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather data is on an daily basis, not hourly, which is too bad especially for the precipitation. We need to resample to an hourly frequency to match our bike data. For the temperature I interpolate with a second order polynomial, since it should vary smoothly. For precipitation I choose a linear interpretation instead. The values from the weather data are placed at noon, and the interpolation fills the gaps between noons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf_resampled = wdf.resample(\"1h\", loffset=\"12h\").mean().reindex(times)\n",
    "# The .bfill and .ffill fill the first and last half a day with the values of the\n",
    "# first and last data point.\n",
    "wdf_resampled[\"TAVG\"] = (\n",
    "    wdf_resampled[\"TAVG\"]\n",
    "    .interpolate(method=\"polynomial\", order=2)\n",
    "    .bfill()\n",
    "    .ffill()\n",
    ")\n",
    "wdf_resampled[\"PRCP\"] = (\n",
    "    wdf_resampled[\"PRCP\"].interpolate(method=\"linear\").bfill().ffill()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this data is predictors, we normalize them to have variance one, and for the average temperature also a mean of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdfn = wdf_resampled.copy()\n",
    "wdfn[\"PRCP\"] /= wdfn[\"PRCP\"].std()\n",
    "wdfn[\"TAVG\"] = (wdfn[\"TAVG\"] - wdfn[\"TAVG\"].mean()) / wdfn[\"TAVG\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to see if adding the weather data is a predictor makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n"
     ]
    }
   ],
   "source": [
    "predictors_dumw = pd.concat([predictors_dum, wdfn], axis=1)\n",
    "rv_dumw = RollingValidator(\n",
    "    data[test_columns],\n",
    "    predictors_dumw,\n",
    "    specific_predictors,\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonGLM\n",
      "MAE: 11.371\n"
     ]
    }
   ],
   "source": [
    "print(PoissonGLM.classname)\n",
    "err = rv_dumw.test_modelclass(PoissonGLM)\n",
    "print(\"MAE: {:.3f}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it does, but a very small one. Surprisinly so, if you ask me. The difference becomes much more drastic if you leave out the dummy variables for months of the year and then rerun with and without weather data, since much of the variation of the year is really variation due to average temperature. But I'm still surprised that having knowledge of exceptionally rainy or cold/warm days doesn't give us a bigger edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice feature of statistical models like Poisson regression, compared to generic machine learning methods, is that they provide superior interpretability, and allow things like hypothesis testing. We can make use of that to find out whether weather really makes a difference for bike usage. To that end, I take two columns, departures from Waterloo (primarily a commuter station) and Hyde Park Corner (primarily a leisure station), fit a Poisson regression model to the whole time range, and print out the coefficients that the temperature and precipitation columns get in the log-linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2848: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  raw_cell, store_history, silent, shell_futures)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Waterloo Station 3, Waterloo', 'Start')\n",
      "                                                coef    std err          z      P>|z|      [0.005      0.995]\n",
      "PRCP                                         -0.0252      0.002    -15.891      0.000      -0.029      -0.021\n",
      "TAVG                                          0.0489      0.003     16.549      0.000       0.041       0.056\n",
      "('Hyde Park Corner, Hyde Park', 'Start')\n",
      "                                               coef    std err          z      P>|z|      [0.005      0.995]\n",
      "PRCP                                        -0.0866      0.002    -50.055      0.000      -0.091      -0.082\n",
      "TAVG                                         0.2853      0.003     96.175      0.000       0.278       0.293\n"
     ]
    }
   ],
   "source": [
    "summary_columns = [\n",
    "    (\"Waterloo Station 3, Waterloo\", \"Start\"),\n",
    "    (\"Hyde Park Corner, Hyde Park\", \"Start\"),\n",
    "]\n",
    "alpha = 0.01  # The signifcance level.\n",
    "for column in summary_columns:\n",
    "    predictors = pd.concat(\n",
    "        [predictors_dumw, events_offset[column]], axis=1\n",
    "    )\n",
    "    glm_poisson = sm.GLM(\n",
    "        data[column], predictors, family=sm.families.Poisson(),\n",
    "    )\n",
    "    print(column)\n",
    "    model = glm_poisson.fit()\n",
    "    lines = str(model.summary(alpha=alpha)).split(\"\\n\")\n",
    "    print(lines[12])\n",
    "    for l in lines:\n",
    "        if \"PRCP\" in l or \"TAVG\" in l:\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most interesting here are the confidence intervals on the right, that confirm that both precipitation and average temperature have a non-zero effect on bike usage with statistical signifcance at the 1% level, at the least. This is so even though our model includes as independent variables dummies for months of the year, which certainly are correlated with at least temperature. Note also that the effect is markedly larger for Hyde Park than for Waterloo, both with temperature and precipitation, as one would expect: Leisurely cyclists are more easily deterred by weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test and conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up, let's take our favourite model, Poisson regression with weather included, and do predictions on both the arrivals to and departures for a couple of stations we haven't looked at yet: Belgrove Street, King's Cross and Black Lion Gate, Kensington Gardens, both of which are among the busiest in town. Let's also do prediction in smaller chunks, 30 days at once, to hopefully increase accuracy. After all, if this was a real usage scenario, there would be no reason not to refit with the latest data every night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a RollingValidator with 40 cross-validation batches.\n",
      "Created a RollingValidator with 40 cross-validation batches.\n",
      "Created a RollingValidator with 40 cross-validation batches.\n",
      "Created a RollingValidator with 40 cross-validation batches.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.862773854677208"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stations = [\"Belgrove Street , King's Cross\", \"Black Lion Gate, Kensington Gardens\"]\n",
    "min_training_time = 2 * pd.Timedelta(\"365d\")\n",
    "prediction_time = pd.Timedelta(\"30d\")\n",
    "rv_test = RollingValidator(\n",
    "    data[test_stations],\n",
    "    predictors_dumw,\n",
    "    events_offset[test_stations],\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")\n",
    "err = rv_test.test_modelclass(PoissonGLM)\n",
    "print(\"MAE: {:.3f}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That mean absolute error can be contrasted with the average number of events per hour for the same stations, which is roughly twice as large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 34.801\n"
     ]
    }
   ],
   "source": [
    "mean = data[test_stations].sum(axis=1).mean()\n",
    "print(\"Mean: {:.3f}\".format(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an illustration of what our predictions are capable of, using them same February week as an example that we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/seaborn/axisgrid.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd677d64ea7430795b8f10b228a5055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/seaborn/axisgrid.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c55e9596db048ed893ec101d810ca9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timewindow = slice(\"2017-02-20\", \"2017-02-26\")\n",
    "prediction = pd.concat(\n",
    "    rv_test.models[\"PoissonGLM\"][\"test_predictions\"]\n",
    ").sort_index()[timewindow]\n",
    "outcome = data[test_stations].reindex(prediction.index)[timewindow]\n",
    "outcome = (\n",
    "    outcome.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"End/Start\", 0: \"Outcome\"})\n",
    ")\n",
    "prediction = (\n",
    "    prediction.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\"level_1\": \"Station\", \"level_2\": \"End/Start\", 0: \"Prediction\"}\n",
    "    )\n",
    ")\n",
    "comparison = pd.merge(prediction, outcome, on=[\"Date\", \"Station\", \"End/Start\"])\n",
    "comparison = comparison.melt(id_vars=[\"Date\", \"Station\", \"End/Start\"]).rename(\n",
    "    columns={\"value\": \"Bike count\", \"variable\": \"Prediction/Outcome\"}\n",
    ")\n",
    "for station in test_stations:\n",
    "    plot_data = comparison[comparison[\"Station\"] == station]\n",
    "    g = sns.FacetGrid(\n",
    "        plot_data,\n",
    "        col_wrap=1,\n",
    "        col=\"End/Start\",\n",
    "        hue=\"Prediction/Outcome\",\n",
    "        aspect=2.0,\n",
    "        sharey=False,\n",
    "        sharex=True,\n",
    "    )\n",
    "    g.map(plt.plot, \"Date\", \"Bike count\").set_titles(station + \", {col_name}\")\n",
    "    g.add_legend()\n",
    "    plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there are many additional things one could do to try to improve the predictions. The model selection process here has been very ad hoc and unsystematic, as was feature selection. I suspect that especially toying around with features, trying different combinations of autoregressive and seasonal predictors could be helpful. Overfitting hasn't been a huge a problem so far, so we could afford adding more predictors. We could also try improve our Poisson regression model, by for instance going beyond the log-linear model for the mean. I'm especially tempted to try to make a Bayesian variant of the same idea, that would run in \"real time\" through the data set from start to finish, and update its coefficients as it progresses and gains new knowledge. We shall see whether I find the time to do that.\n",
    "\n",
    "I hope you, my dear reader, have learned something about either Boris Bikes or time series regression through this project. I've certainly learned much. At the start of this project I had never used scikit-learn, didn't know what Poisson regression is, and hadn't ever really seriously worked with statistical models and things like confidence intervals, so it's been quite an intense schooling. I certainly enjoyed it though, I hope you did as well. If you end up analysing the same data, building on what I've done hear, please let me know: [markus@mhauru.org](mailto:markus@mhauru.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0045aaca24db4d0ea6e5db8e0b2faf1e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_078988dc54be4a27821a9778bcee542b",
       "toolbar": "IPY_MODEL_d0d2df4b992747268e0992eac598cae7",
       "toolbar_position": "left"
      }
     },
     "01124b75685047c2b46e90e5483a7e2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "01bedf1b23ab40e6a023bc324bc77bf7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_74d2f2b5b8ac4d18a1a1fe32bb08fd1e",
       "toolbar": "IPY_MODEL_08d6e99603b14900b0ecba4cc315c544",
       "toolbar_position": "left"
      }
     },
     "01d150376bec4362b443dd8a54779f39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "063ca65cb2d4433d94a131316861017b": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_d58e56e0bce845f29ca9901fe5e13e0c",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "0727f267bbed47129d21f8005ec6849c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "07777d6d45ed4cae9db129ff8bcdd6ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "078988dc54be4a27821a9778bcee542b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "08d0c3e91b9549c4b47202ba31dedb9c": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_ed8cd931d75344bfb4393035a80fe4cd",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "08d6e99603b14900b0ecba4cc315c544": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_53372a172a0e4e78878069e382351da3",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "0949d53624f04877abdd1a59cfd79c43": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_407e98adc48c4ced9de28b1e9fae6b53",
       "toolbar": "IPY_MODEL_7736afb220a44c77b5e9b4523a091679",
       "toolbar_position": "left"
      }
     },
     "0a38e13db2114b77a3fa349598e93c97": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_41b80c82375e4d94a76cb1d86fde0811",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "0bce9287190843e68dd0806876c2e03e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_ae44ad6d8b5b408c919a984b239fc392",
       "toolbar": "IPY_MODEL_64ee41fd16e4459b9d5d9951c88248bf",
       "toolbar_position": "left"
      }
     },
     "0ee5f121214147ffb12bcce2a2678851": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "10ea14eed7034d16bbffa7e1ec8896ee": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_cecf0c0699c548bcb97f6f71cdf886b8",
       "toolbar": "IPY_MODEL_9f3623e6e7ee4f22be8a1355cad402ac",
       "toolbar_position": "left"
      }
     },
     "127c65fe9c1945bfb81850c40898d090": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "14b1e53f37c647d2961b3e82a888836e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "184ea672515b41f8b170207fa2692670": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_0727f267bbed47129d21f8005ec6849c",
       "toolbar": "IPY_MODEL_4837c6e8cd57490dbb8f13049a160623",
       "toolbar_position": "left"
      }
     },
     "186f4051987c49038f4d7031d4d1eac5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18bea46c7fc64672bcdb9e070eea696c": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_a7dfda0b86954c5e882dcca6cb4a27cb",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "19c0da518c53434b9b12cb752147f461": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_7f8f3b65212846e1902c722c50f93a15",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "1a053fa82e614fe5a0b07ca902ee4c32": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_3e6420cd9d40455ba51c2223c56f872c",
       "toolbar": "IPY_MODEL_0a38e13db2114b77a3fa349598e93c97",
       "toolbar_position": "left"
      }
     },
     "1ec27896aab84cfa976f3a79ce10def7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_5de08c7abf6949029331fb35e295b42b",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "1fccfe6c5acd4bd78205836f83391e22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21df3f0707264fc1b9817630e2150e40": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_d94496f47170458fbc803e664cd539f6",
       "toolbar": "IPY_MODEL_28a2b4163aaa4115abbdef244606e34c",
       "toolbar_position": "left"
      }
     },
     "271b21a193ac43449f0ee9e6634c28d0": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_e46ace57db834b86b71b87364022b133",
       "toolbar": "IPY_MODEL_ae5fa7cbd9ac4f1ca5e67d8dba7d1890",
       "toolbar_position": "left"
      }
     },
     "27a38b0759074b349e584e615fe253a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "28a2b4163aaa4115abbdef244606e34c": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_e62d34fb87d8484d91eefd8b61008a20",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "296eab9a818a47b082a89477037a1042": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2be1ed59d0b14a26ace1bd382712a253": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_40a710dfd9a54ffe8c1b157aac209e26",
       "toolbar": "IPY_MODEL_18bea46c7fc64672bcdb9e070eea696c",
       "toolbar_position": "left"
      }
     },
     "2d726349d05140aaa1575322bf8ca5b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2de6217a700f48ee8cdc8e2d7f890402": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e600a281f854a0e9dfd8765016aac48": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_a79d25f597ba40aca10670e80501a28e",
       "toolbar": "IPY_MODEL_783c6a1275ec41d599aedca9aecb4755",
       "toolbar_position": "left"
      }
     },
     "30f3d872d39846b78d3d25bf4cbf57e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "31631da8a16e424fab8f128567c6b763": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "318a1e80d3a949ac9a563c7dc1f4b05c": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_b3bf415b68fa4859bda80b5ce3d08e6c",
       "toolbar": "IPY_MODEL_7dd5173173454bfbb97e6ed23764463d",
       "toolbar_position": "left"
      }
     },
     "31fc9b2db42c45d7b73af28d894edcdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "38b8994f4cbe4b3dbe98451903b08bb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3c3d932f2ba94df5bf4320b8285c18e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d40a839b7a44fd69cf33164f237cd6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e50866886e645769b4bb60f3702c62f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e6420cd9d40455ba51c2223c56f872c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3fb75876c0894d5bb365ab5ae405e218": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_4c9c74146b1b4b72a98ad9ac294cd662",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "3fe4645ea6dd49b58585577f4b4e7bdb": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_aadba5bd61794bde8de6fe93401197df",
       "toolbar": "IPY_MODEL_7a72d921e54f44f7aa7d4104d8b247ce",
       "toolbar_position": "left"
      }
     },
     "403cef864e1f418fa2ef8fe6a154a47e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c3b216cf085049d999e842448aef637f",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "407e98adc48c4ced9de28b1e9fae6b53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40a710dfd9a54ffe8c1b157aac209e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "41b80c82375e4d94a76cb1d86fde0811": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43791722ac6b4e63b239f04aa04e2a9b": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_cf84672fed614a9bbad560065eed71ed",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "46fbc3270ef444fea827f5014eb3e274": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_27a38b0759074b349e584e615fe253a3",
       "toolbar": "IPY_MODEL_5a154b1b926d4483a5a3ac5ddd3feda5",
       "toolbar_position": "left"
      }
     },
     "4706f25298464d1f861c3351da6deef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "472fad82d1244178acbecaf14890bf51": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_127c65fe9c1945bfb81850c40898d090",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "4837c6e8cd57490dbb8f13049a160623": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_6bb49717e0544f33aaba901fb7472b8c",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "49a75e18684b4186a7899f108be8aaa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "49b65e0c7b7244d9be25bd1d32cf990e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4c9c74146b1b4b72a98ad9ac294cd662": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4e533b97c48f48e9aad46c5b3040a4fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "505025d159894b09b6787245c0c14ced": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "51fdd04a7c0e48359bf383ba002bf089": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "53372a172a0e4e78878069e382351da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5a154b1b926d4483a5a3ac5ddd3feda5": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_974b56b75a9c47da9654d346a330154f",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "5ad3cc19fc9f4b109e2e94511d9e0897": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_ec1f3526c27144b18375af45fb333d67",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "5de08c7abf6949029331fb35e295b42b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6030a8b935cc47adbf93d92675860478": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "64ee41fd16e4459b9d5d9951c88248bf": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_505025d159894b09b6787245c0c14ced",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "67e2d5ad69094f7e8ca52cbf2eb7fdba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6b10ec02f31b4614baac9cb35ecf1fd9": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_4706f25298464d1f861c3351da6deef4",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "6bb49717e0544f33aaba901fb7472b8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6cf05383b4344541a9e05d2b3cd25a38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6d38cbfa8072489da9bf8725e8a865f7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_6030a8b935cc47adbf93d92675860478",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "6e73ae60b7434631b911fadd186a7b19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "70f5c31210a5440fbe0ccee62eafea5b": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_92aabff7a3d749058d1196f1b7731560",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "730573c833f44367a2f5497497f10c23": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_bdd90dbe5bfe4b20a464f7e267086eaa",
       "toolbar": "IPY_MODEL_da4d218fa26f436ea14ce6aa95261c8c",
       "toolbar_position": "left"
      }
     },
     "73d6c699c19f4b0b9661056d63110a19": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_a94a2293f64c4c599ffffad9d8e28448",
       "toolbar": "IPY_MODEL_43791722ac6b4e63b239f04aa04e2a9b",
       "toolbar_position": "left"
      }
     },
     "747f42d0747644488b8f42ac64242b59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "74d2f2b5b8ac4d18a1a1fe32bb08fd1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7736afb220a44c77b5e9b4523a091679": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_3e50866886e645769b4bb60f3702c62f",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "783c6a1275ec41d599aedca9aecb4755": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_01124b75685047c2b46e90e5483a7e2a",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "79b4aa0501a24717a9884341f2502961": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7a72d921e54f44f7aa7d4104d8b247ce": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_cf5d43dd78064ed78e177c7ebb9a9749",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "7bd677d64ea7430795b8f10b228a5055": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_a44cf423cfb746649afb36bb399c095f",
       "toolbar": "IPY_MODEL_f8bc0b15634541e886f3fc729afe1bd0",
       "toolbar_position": "left"
      }
     },
     "7dd5173173454bfbb97e6ed23764463d": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_db31ddf95266404999ebb3d7dfb87e25",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "7f8f3b65212846e1902c722c50f93a15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7ff3ea4231614d15a4c9f1843be356ee": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_31fc9b2db42c45d7b73af28d894edcdd",
       "toolbar": "IPY_MODEL_92f325c63fc242c6a825b4cad69cc444",
       "toolbar_position": "left"
      }
     },
     "7ffb82c21e824fd3a35e9a739f958a3f": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_49a75e18684b4186a7899f108be8aaa4",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "82200b77fcea4f02b33f55bceabdece0": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_c55aeac93b0f44aeb5d5033ecd96a191",
       "toolbar": "IPY_MODEL_ab6066df9a9e4c64a563a0750aee2164",
       "toolbar_position": "left"
      }
     },
     "83e6473f367940708cc7262690c5c88e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84a396344b9e49579375f92bbd7363ca": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_e558562008d447e89f24c368911ce3f8",
       "toolbar": "IPY_MODEL_7ffb82c21e824fd3a35e9a739f958a3f",
       "toolbar_position": "left"
      }
     },
     "8658fd896d944dd196851d325b996722": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_9636e12d2dc94b13a52ac58fc454a162",
       "toolbar": "IPY_MODEL_ef9182d3f88249b2b2a4ec7445831f26",
       "toolbar_position": "left"
      }
     },
     "89f58755a78a44baa7e7ca2bd331a37a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_83e6473f367940708cc7262690c5c88e",
       "toolbar": "IPY_MODEL_9820f54e97954bc5a7b3318376fcc2c3",
       "toolbar_position": "left"
      }
     },
     "8a469bb7093a4a0d88726ee4f7ebd56f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8d082c8904b94237be383c490048ad0e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_79b4aa0501a24717a9884341f2502961",
       "toolbar": "IPY_MODEL_08d0c3e91b9549c4b47202ba31dedb9c",
       "toolbar_position": "left"
      }
     },
     "8d8e8fb199dc40aa8e822ab7decf8f51": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_ee27cd35bcdf432cb8478e7fc02dd880",
       "toolbar": "IPY_MODEL_b15f5651ea674e2fb06da925b29a26e7",
       "toolbar_position": "left"
      }
     },
     "8ec0c5a3a40d4221a9097f6e4200f8e3": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_6e73ae60b7434631b911fadd186a7b19",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "8fcfc29fee264573a0083b55ee5a9bbe": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_d578b407a6ce4e64b482999bbf9fc556",
       "toolbar": "IPY_MODEL_d36bfbff2f7e4e6898a3641b3028055a",
       "toolbar_position": "left"
      }
     },
     "91846596adaa40f988ee51f47f353118": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_186f4051987c49038f4d7031d4d1eac5",
       "toolbar": "IPY_MODEL_cc39cf094a80469eaa845ddca0fd9398",
       "toolbar_position": "left"
      }
     },
     "91e1989336404477a7dcd666d333c8f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92aabff7a3d749058d1196f1b7731560": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92c657a5f3d6434c9c3c8c0375e02732": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_0ee5f121214147ffb12bcce2a2678851",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "92f325c63fc242c6a825b4cad69cc444": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_38b8994f4cbe4b3dbe98451903b08bb2",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "945ef465ea104e77af6bde88bd757aaf": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_1fccfe6c5acd4bd78205836f83391e22",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9636e12d2dc94b13a52ac58fc454a162": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "974b56b75a9c47da9654d346a330154f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9820f54e97954bc5a7b3318376fcc2c3": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_bcb35843fd074679927e36400dc686c6",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9c55e9596db048ed893ec101d810ca9e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_b382bf9866fa47238cf3cc587d6673ca",
       "toolbar": "IPY_MODEL_063ca65cb2d4433d94a131316861017b",
       "toolbar_position": "left"
      }
     },
     "9f332b34717d4e97a1a8d4f77b68847a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_2d726349d05140aaa1575322bf8ca5b7",
       "toolbar": "IPY_MODEL_5ad3cc19fc9f4b109e2e94511d9e0897",
       "toolbar_position": "left"
      }
     },
     "9f3623e6e7ee4f22be8a1355cad402ac": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_01d150376bec4362b443dd8a54779f39",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9f52129eeaa44cf0b375b585aa6c860a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_49b65e0c7b7244d9be25bd1d32cf990e",
       "toolbar": "IPY_MODEL_fe3fa83494f4475fa713e6ee93358b48",
       "toolbar_position": "left"
      }
     },
     "a2d932005e0942eeb34975985637a05a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_6cf05383b4344541a9e05d2b3cd25a38",
       "toolbar": "IPY_MODEL_19c0da518c53434b9b12cb752147f461",
       "toolbar_position": "left"
      }
     },
     "a44cf423cfb746649afb36bb399c095f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a51789c371054111889d84045c85c30e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a544b9eca0124b0284faf5d0d86dd2e2": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_b4b79e72752240fd87d35c248303c213",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "a555fd5ea5f94bca84af3229bdcfab8b": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_2de6217a700f48ee8cdc8e2d7f890402",
       "toolbar": "IPY_MODEL_dabbe6bbb05143c788cf802c7542aa82",
       "toolbar_position": "left"
      }
     },
     "a5ceb0e3f64644e2a7d57d7586634cd3": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_51fdd04a7c0e48359bf383ba002bf089",
       "toolbar": "IPY_MODEL_dca7927b1e36420c93a482aca9754059",
       "toolbar_position": "left"
      }
     },
     "a79d25f597ba40aca10670e80501a28e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a7dfda0b86954c5e882dcca6cb4a27cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a94a2293f64c4c599ffffad9d8e28448": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aadba5bd61794bde8de6fe93401197df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aaddc8d88c5044588b0416af3492ce3f": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_f6fa51387f1b433590546fb73b246b61",
       "toolbar": "IPY_MODEL_6d38cbfa8072489da9bf8725e8a865f7",
       "toolbar_position": "left"
      }
     },
     "ab0339fe00a84ccf9eae1e023436450c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ab6066df9a9e4c64a563a0750aee2164": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_a51789c371054111889d84045c85c30e",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "ad32453ad5064e78aeab71453ea0c6f7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_ab0339fe00a84ccf9eae1e023436450c",
       "toolbar": "IPY_MODEL_92c657a5f3d6434c9c3c8c0375e02732",
       "toolbar_position": "left"
      }
     },
     "ae44ad6d8b5b408c919a984b239fc392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae5fa7cbd9ac4f1ca5e67d8dba7d1890": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_14b1e53f37c647d2961b3e82a888836e",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "b15f5651ea674e2fb06da925b29a26e7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_ff17faf8f03d42d4b9a6879fce0dc4ed",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "b208cbfea12640f99412f7306040ff53": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_67e2d5ad69094f7e8ca52cbf2eb7fdba",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "b382bf9866fa47238cf3cc587d6673ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b3bf415b68fa4859bda80b5ce3d08e6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b3efe83185a048a99f08a19d6b7c3e2e": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_8a469bb7093a4a0d88726ee4f7ebd56f",
       "toolbar": "IPY_MODEL_a544b9eca0124b0284faf5d0d86dd2e2",
       "toolbar_position": "left"
      }
     },
     "b46fc0cbeb41480e9120696c2557dbd4": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_296eab9a818a47b082a89477037a1042",
       "toolbar": "IPY_MODEL_fc2494fd2f42404b9b23c396a4303330",
       "toolbar_position": "left"
      }
     },
     "b4b79e72752240fd87d35c248303c213": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb3b8967331b40b895eae7ef0317140b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bbdb2b01b695468b9f7a258eb300b942": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bcb35843fd074679927e36400dc686c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bdd90dbe5bfe4b20a464f7e267086eaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c1b90e647b0344abb612eb944d21995b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c320e12cc2df432581382609c19a9e7a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_ec7eb77edcb148f687e320955063b028",
       "toolbar": "IPY_MODEL_472fad82d1244178acbecaf14890bf51",
       "toolbar_position": "left"
      }
     },
     "c33cf7bf284545889c8d0e24516c6e4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c3b216cf085049d999e842448aef637f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c4cb2ee7d94e4105b30f872044337a7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c55aeac93b0f44aeb5d5033ecd96a191": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c633aaae409843e287f2d319c22508d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c64f82b52f2640859a56392dee16dcc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c70f81a9d2db4beb98e628e82c977173": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_c4cb2ee7d94e4105b30f872044337a7d",
       "toolbar": "IPY_MODEL_6b10ec02f31b4614baac9cb35ecf1fd9",
       "toolbar_position": "left"
      }
     },
     "cc39cf094a80469eaa845ddca0fd9398": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_e5966ca61d79402aafa197c5b5c08e54",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "cce2d917809c48e5949f696b705c299a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_4e533b97c48f48e9aad46c5b3040a4fc",
       "toolbar": "IPY_MODEL_3fb75876c0894d5bb365ab5ae405e218",
       "toolbar_position": "left"
      }
     },
     "ccfa516348f342ffb4b2945d5965291d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cecf0c0699c548bcb97f6f71cdf886b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf5d43dd78064ed78e177c7ebb9a9749": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf84672fed614a9bbad560065eed71ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d0d2df4b992747268e0992eac598cae7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_747f42d0747644488b8f42ac64242b59",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "d36bfbff2f7e4e6898a3641b3028055a": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c64f82b52f2640859a56392dee16dcc7",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "d40a18ac32f74f59a07e9459a23e4722": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_31631da8a16e424fab8f128567c6b763",
       "toolbar": "IPY_MODEL_b208cbfea12640f99412f7306040ff53",
       "toolbar_position": "left"
      }
     },
     "d578b407a6ce4e64b482999bbf9fc556": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d58e56e0bce845f29ca9901fe5e13e0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d94496f47170458fbc803e664cd539f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "da4651a590e74cb2a3de2b04214689eb": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_c33cf7bf284545889c8d0e24516c6e4c",
       "toolbar": "IPY_MODEL_8ec0c5a3a40d4221a9097f6e4200f8e3",
       "toolbar_position": "left"
      }
     },
     "da4d218fa26f436ea14ce6aa95261c8c": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c1b90e647b0344abb612eb944d21995b",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "dabbe6bbb05143c788cf802c7542aa82": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_3d40a839b7a44fd69cf33164f237cd6a",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "db31ddf95266404999ebb3d7dfb87e25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dca7927b1e36420c93a482aca9754059": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_ccfa516348f342ffb4b2945d5965291d",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "dd3156573ca844038d46e40f8d3a01e9": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_f444e421a341442893aac3b419beb601",
       "toolbar": "IPY_MODEL_1ec27896aab84cfa976f3a79ce10def7",
       "toolbar_position": "left"
      }
     },
     "dd787b2dd6d546d38b32c6ffbf160621": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_3c3d932f2ba94df5bf4320b8285c18e2",
       "toolbar": "IPY_MODEL_945ef465ea104e77af6bde88bd757aaf",
       "toolbar_position": "left"
      }
     },
     "e46ace57db834b86b71b87364022b133": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e558562008d447e89f24c368911ce3f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e5966ca61d79402aafa197c5b5c08e54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e62d34fb87d8484d91eefd8b61008a20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb3d48a5848b403c93e24fdd9c83338d": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_07777d6d45ed4cae9db129ff8bcdd6ae",
       "toolbar": "IPY_MODEL_70f5c31210a5440fbe0ccee62eafea5b",
       "toolbar_position": "left"
      }
     },
     "ec1f3526c27144b18375af45fb333d67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec7eb77edcb148f687e320955063b028": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ed8cd931d75344bfb4393035a80fe4cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ee27cd35bcdf432cb8478e7fc02dd880": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef9182d3f88249b2b2a4ec7445831f26": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_bb3b8967331b40b895eae7ef0317140b",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "f444e421a341442893aac3b419beb601": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6fa51387f1b433590546fb73b246b61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f8bc0b15634541e886f3fc729afe1bd0": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_91e1989336404477a7dcd666d333c8f5",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "f920d38d4cac4c5d88348a667e0acd43": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_30f3d872d39846b78d3d25bf4cbf57e2",
       "toolbar": "IPY_MODEL_403cef864e1f418fa2ef8fe6a154a47e",
       "toolbar_position": "left"
      }
     },
     "fc2494fd2f42404b9b23c396a4303330": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c633aaae409843e287f2d319c22508d4",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "fe3fa83494f4475fa713e6ee93358b48": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_bbdb2b01b695468b9f7a258eb300b942",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "ff17faf8f03d42d4b9a6879fce0dc4ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
