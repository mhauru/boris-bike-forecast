{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other analyses of the same data:\n",
    "\n",
    "https://github.com/charlie1347/TfL_bikes\n",
    "\n",
    "https://medium.com/@AJOhrn/data-footprint-of-bike-sharing-in-london-be9e11425248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm, neighbors, naive_bayes, tree\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pretty and exportable matplotlib plots.\n",
    "# If you are running this yourself and want interactivity,\n",
    "# try `%matplotlib widget` instead.\n",
    "# set_matplotlib_formats(\"svg\")\n",
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "# Set a consistent plotting style across the notebook using Seaborn.\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikefolder = \"./data/bikes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_station_names(station_names, df, namecolumn, idcolumn):\n",
    "    namemaps = (\n",
    "        df[[idcolumn, namecolumn]]\n",
    "        .groupby(idcolumn)\n",
    "        .aggregate(lambda x: x.unique())\n",
    "    )\n",
    "    for number, names in namemaps.iterrows():\n",
    "        current_names = station_names.get(number, set())\n",
    "        # The following two lines are a stupid dance around the annoying fact that pd.unique sometimes returns a single value,\n",
    "        # sometimes a numpy array of values, but since the single value is a string, it too is an iterable.\n",
    "        vals = names[0]\n",
    "        new_names = set([vals]) if type(vals) == str else set(vals)\n",
    "        current_names.update(new_names)\n",
    "        station_names[number] = current_names\n",
    "\n",
    "\n",
    "def clean_datetime_column(df, colname, roundto=\"H\"):\n",
    "    # A bit of a hacky way to use the first entry to figure out which date format this file uses.\n",
    "    # Not super robust, but works. TODO Improve this.\n",
    "    if len(df[colname].iloc[0]) > 16:\n",
    "        format = \"%d/%m/%Y %H:%M:%S\"\n",
    "    else:\n",
    "        format = \"%d/%m/%Y %H:%M\"\n",
    "    df[colname] = pd.to_datetime(df[colname], format=format)\n",
    "    df[colname] = df[colname].dt.round(roundto)\n",
    "    early_cutoff = pd.datetime(2010, 7, 30)  # When the program started.\n",
    "    late_cutoff = pd.datetime(2020, 1, 1)  # Approximately now.\n",
    "    df = df[(late_cutoff > df[colname]) & (df[colname] >= early_cutoff)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_single_events(df, which):\n",
    "    stationcol = \"{}Station Id\".format(which)\n",
    "    datecol = \"{} Date\".format(which)\n",
    "    events = (\n",
    "        df.rename(columns={stationcol: \"Station\", datecol: \"Date\"})\n",
    "        .groupby([\"Date\", \"Station\"])\n",
    "        .size()\n",
    "        .unstack(\"Station\")\n",
    "    )\n",
    "    return events\n",
    "\n",
    "\n",
    "def compute_both_events(df):\n",
    "    ends = compute_single_events(df, \"End\")\n",
    "    starts = compute_single_events(df, \"Start\")\n",
    "    both = (\n",
    "        pd.concat([ends, starts], keys=[\"End\", \"Start\"], axis=1)\n",
    "        .reorder_levels([1, 0], axis=1)\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "    return both\n",
    "\n",
    "\n",
    "def castable_to_int(obj):\n",
    "    try:\n",
    "        int(obj)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def cast_to_int(df, colname):\n",
    "    try:\n",
    "        df = df.astype({colname: np.int_}, copy=False)\n",
    "    except ValueError:\n",
    "        castable_rows = df[colname].apply(castable_to_int)\n",
    "        df = df[castable_rows]\n",
    "        df = df.astype({colname: np.int_}, copy=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "events_by_station_path = Path(\"./events_by_station.p\")\n",
    "if events_by_station_path.exists():\n",
    "    events_by_station = pd.read_pickle(events_by_station_path)\n",
    "else:\n",
    "    datafiles = sorted(os.listdir(bikefolder))\n",
    "    folderpath = Path(bikefolder)\n",
    "    datapaths = [folderpath / Path(file) for file in datafiles]\n",
    "    datapaths = [p for p in datapaths if p.suffix == \".csv\"]\n",
    "\n",
    "    station_allnames = {}\n",
    "\n",
    "    pieces = []\n",
    "    #     datapaths = [\n",
    "    #         folderpath / Path(file)\n",
    "    #         for file in [\n",
    "    #             \"21JourneyDataExtract31Aug2016-06Sep2016.csv\",\n",
    "    #             \"15JourneyDataExtract20Jul2016-26Jul2016.csv\",\n",
    "    #             \"13b. Journey Data Extract 22Dec14-03Jan15.csv\",\n",
    "    #             \"16JourneyDataExtract27Jul2016-02Aug2016.csv\",\n",
    "    #             \"10b. Journey Data Extract 28Sep14-11Oct14.csv\",\n",
    "    #             \"6. Journey Data Extract_27May-23Jun12.csv\",\n",
    "    #             \"6. Journey Data Extract_27May-23Jun12.csv\",\n",
    "    #         ]\n",
    "    #     ]\n",
    "    cols = [\n",
    "        \"Duration\",\n",
    "        \"End Date\",\n",
    "        \"EndStation Id\",\n",
    "        \"EndStation Name\",\n",
    "        \"Start Date\",\n",
    "        \"StartStation Id\",\n",
    "        \"StartStation Name\",\n",
    "    ]\n",
    "    problem_paths = []\n",
    "    for path in datapaths:\n",
    "        print(path)\n",
    "        try:\n",
    "            df = pd.read_csv(path, usecols=cols, encoding=\"ISO-8859-2\")\n",
    "        except ValueError as e:\n",
    "            # Some files have missing or abnormaly named columns. We'll deal with them later.\n",
    "            problem_paths.append(path)\n",
    "            continue\n",
    "        # Drop any rows that have missing values.\n",
    "        df = df[~df.isna().any(axis=1)]\n",
    "        # Drop any anomalously short trips. Probably somebody just taking a bike and putting\n",
    "        # it right back in.\n",
    "        df = df[df[\"Duration\"] > 60]\n",
    "        # Cast the columns to the right types. This is easier ones NAs have been dropped.\n",
    "        df = cast_to_int(df, \"EndStation Id\")\n",
    "        df = cast_to_int(df, \"StartStation Id\")\n",
    "        # Turn the date columns from strings into datetime objects rounded to the hour.\n",
    "        df = clean_datetime_column(df, \"End Date\")\n",
    "        df = clean_datetime_column(df, \"Start Date\")\n",
    "        events = compute_both_events(df)\n",
    "        pieces.append(events)\n",
    "\n",
    "        add_station_names(\n",
    "            station_allnames, df, \"EndStation Name\", \"EndStation Id\"\n",
    "        )\n",
    "        add_station_names(\n",
    "            station_allnames, df, \"StartStation Name\", \"StartStation Id\"\n",
    "        )\n",
    "\n",
    "    station_ids = {}\n",
    "    station_names = {}\n",
    "    for k, v in station_allnames.items():\n",
    "        v = sorted(v)\n",
    "        station_names[k] = v[0]\n",
    "        for name in v:\n",
    "            station_ids[name] = k\n",
    "\n",
    "    def get_station_id(name):\n",
    "        try:\n",
    "            return station_ids[name]\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "\n",
    "    print(\"Doing the problem cases ({} of them).\".format(len(problem_paths)))\n",
    "    safe_cols = [\n",
    "        \"Duration\",\n",
    "        \"End Date\",\n",
    "        \"EndStation Name\",\n",
    "        \"Start Date\",\n",
    "        \"StartStation Name\",\n",
    "    ]\n",
    "    for path in problem_paths:\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, usecols=safe_cols, encoding=\"ISO-8859-2\")\n",
    "        # Drop any rows that have missing values.\n",
    "        df = df[~df.isna().any(axis=1)]\n",
    "        # Drop any anomalously short trips. Probably somebody just taking a bike and putting\n",
    "        # it right back in.\n",
    "        df = df[df[\"Duration\"] > 60]\n",
    "        # Add a column of station ids, based on names.\n",
    "        df[\"EndStation Id\"] = df[\"EndStation Name\"].apply(get_station_id)\n",
    "        df[\"StartStation Id\"] = df[\"StartStation Name\"].apply(get_station_id)\n",
    "        # Turn the date columns from strings into datetime objects rounded to the hour.\n",
    "        clean_datetime_column(df, \"End Date\")\n",
    "        clean_datetime_column(df, \"Start Date\")\n",
    "        events = compute_both_events(df)\n",
    "        pieces.append(events)\n",
    "\n",
    "    events_by_station = pd.concat(pieces).fillna(0.0)\n",
    "    # Several files may have contained entries for the same hour, which means that\n",
    "    # events_by_station has duplicate entries in the index. Get rid of them by summing.\n",
    "    events_by_station = events_by_station.groupby(\"Date\").sum().sort_index()\n",
    "    # Finally rename the columns according to the chosen names for stations.\n",
    "    events_by_station = events_by_station.rename(\n",
    "        mapper=station_names, axis=1, level=0\n",
    "    )\n",
    "\n",
    "    events_by_station.to_pickle(events_by_station_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "Electrical Workshop PS                                      1757.661290\n",
       "PENTON STREET COMMS TEST TERMINAL _ CONTACT MATT McNULTY    1615.675676\n",
       "tabletop1                                                   1066.166667\n",
       "Contact Centre, Southbury House                              780.694737\n",
       "6                                                            567.974684\n",
       "Pop Up Dock 1                                                567.806009\n",
       "Mechanical Workshop Penton                                   223.818810\n",
       "South Quay East, Canary Wharf                                133.732653\n",
       "Westfield Eastern Access Road, Shepherd's Bush                88.865062\n",
       "Thornfield House, Poplar                                      83.572294\n",
       "Fore Street Avenue: Guildhall                                 72.241404\n",
       "Upper Grosvenor Street, Mayfair                               71.496163\n",
       "Courland Grove , Wandsworth Road                              57.658476\n",
       "Manfred Road, East Putney                                     54.785485\n",
       "Aberfeldy Street, Poplar                                      54.169256\n",
       "Grant Road Central, Clapham Junction                          53.220326\n",
       "Castalia Square :Cubitt Town                                  53.208849\n",
       "Stebondale Street, Cubitt Town                                53.143344\n",
       "Here East South, Queen Elizabeth Olympic Park                 49.890323\n",
       "Teviot Street, Poplar                                         47.461839\n",
       "Stewart's Road, Nine Elms                                     47.116626\n",
       "Abbotsbury Road, Holland Park                                 46.465510\n",
       "Clarkson Street :Bethnal Green                                46.455175\n",
       "Malmesbury Road :Bow                                          45.637274\n",
       "Cantrell Road, Bow                                            45.279041\n",
       "Here East North, Queen Elizabeth Olympic Park                 45.240314\n",
       "Bevington Road, North Kensington                              45.214481\n",
       "Lord's, St. John's Wood                                       44.309497\n",
       "Birkenhead Street, King's Cross                               44.122969\n",
       "Knightsbridge, Hyde Park                                      43.761308\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_within_window(s):\n",
    "    starttime = s.ne(0).idxmax()\n",
    "    endtime = s[::-1].ne(0).idxmax()\n",
    "    return s[starttime:endtime].mean()\n",
    "\n",
    "\n",
    "a = events_by_station.sum(axis=1, level=0)\n",
    "(a.max() / a.aggregate(mean_within_window)).sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "improper_stations = [\n",
    "    \"Electrical Workshop PS\",\n",
    "    \"PENTON STREET COMMS TEST TERMINAL _ CONTACT MATT McNULTY\",\n",
    "    \"tabletop1\",\n",
    "    \"Pop Up Dock 1\",\n",
    "    \"6\",\n",
    "    \"Mechanical Workshop Penton\",\n",
    "]\n",
    "events_by_station = events_by_station.drop(improper_stations, axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 02:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16 22:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 00:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46879 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     End  Start  End  Start\n",
       "Date                                       \n",
       "2012-01-04 00:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 01:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 02:00:00  2.0    0.0  0.0    0.0\n",
       "2012-01-04 03:00:00  0.0    0.0  0.0    0.0\n",
       "2012-01-04 04:00:00  0.0    0.0  0.0    0.0\n",
       "...                  ...    ...  ...    ...\n",
       "2017-05-16 22:00:00  1.0    1.0  0.0    0.0\n",
       "2017-05-16 23:00:00  0.0    0.0  0.0    0.0\n",
       "2017-05-17 00:00:00  1.0    0.0  0.0    0.0\n",
       "2017-05-17 01:00:00  0.0    0.0  0.0    0.0\n",
       "2017-05-17 02:00:00  0.0    0.0  0.0    0.0\n",
       "\n",
       "[46879 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO What is up with this?\n",
    "events_by_station[\"Exhibition Road Museums, Knightsbridge\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = events_by_station.columns.get_level_values(0).unique()\n",
    "events_by_time = events_by_station.sum(axis=1, level=1)\n",
    "totals_by_station = events_by_station.sum(axis=0)\n",
    "times = events_by_station.index.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stations = [\n",
    "    \"Waterloo Station 3, Waterloo\",\n",
    "    \"Hyde Park Corner, Hyde Park\",\n",
    "    \"Wenlock Road , Hoxton\",\n",
    "    \"Stonecutter Street, Holborn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c320f9deb6f742ad890641b7df5bbbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Give the plots widths from variance or something like [25%, 75%] limits (what are these called again?).\n",
    "example_means_over_week = (\n",
    "    events_by_station[test_stations]\n",
    "    .groupby([times.dt.weekday, times.dt.hour])\n",
    "    .sum()\n",
    ")\n",
    "example_means_over_week.index.rename([\"Day\", \"Hour\"], inplace=True)\n",
    "example_means_over_week = (\n",
    "    example_means_over_week.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_3\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "example_means_over_week[\"Weekday\"] = example_means_over_week.apply(\n",
    "    lambda x: x[\"Day\"] + x[\"Hour\"] / 24, axis=1,\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    example_means_over_week,\n",
    "    col_wrap=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Weekday\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07eab34a767425f9eba8e7381b70a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Give the plots widths from variance or something like [25%, 75%] limits (what are these called again?).\n",
    "example_means_over_year = (\n",
    "    events_by_station[test_stations].groupby(times.dt.week).sum()\n",
    ")\n",
    "# Leave out the first and last weeks, since they are usually shorter and thus the data isn't comparable.\n",
    "example_means_over_year = example_means_over_year.iloc[1:51]\n",
    "example_means_over_year.index.rename(\"Week\", inplace=True)\n",
    "example_means_over_year = (\n",
    "    example_means_over_year.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    example_means_over_year,\n",
    "    col_wrap=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Week\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb83a0301c5a459d8a4907eac95e9941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yearly_rolling = (\n",
    "    events_by_station.loc[:, test_stations]\n",
    "    .rolling(\"365d\", min_periods=24 * 90)\n",
    "    .mean()\n",
    ")\n",
    "yearly_rolling = (\n",
    "    yearly_rolling.stack(level=[0, 1])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"End/Start\", 0: \"Count\"})\n",
    ")\n",
    "g = sns.FacetGrid(\n",
    "    yearly_rolling,\n",
    "    col_wrap=2,\n",
    "    col=\"Station\",\n",
    "    hue=\"End/Start\",\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    ")\n",
    "g.map(plt.plot, \"Date\", \"Count\").set_titles(\"{col_name}\")\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the extremely strong weekly pattern every station seems to have, one we thing we do straight away is instead of trying to predict the data itself, try to predict the change compared to a week ago. This makes fitting models much easier since they don't have to concentrate on trying to get the shape of the weekly trend right. The data also naturally becomes roughly mean-zero, which is useful for some models. Moreover, the long term trends, which may be entirely unpredictable given the data we have, don't ruin our results once we try to predict week-on-week changes. The only downside is that we have to discard the first week of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingValidator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        common_predictors,\n",
    "        specific_predictors,\n",
    "        min_training_time,\n",
    "        prediction_time,\n",
    "    ):\n",
    "        cv_batches = []\n",
    "        first_time = data.index.min()\n",
    "        last_time = data.index.max()\n",
    "        test_end_time = last_time\n",
    "        cutoff = test_end_time - prediction_time\n",
    "        while cutoff > first_time + min_training_time:\n",
    "            training_data = data[:cutoff]\n",
    "            training_common_predictors = common_predictors[:cutoff]\n",
    "            training_specific_predictors = specific_predictors[:cutoff]\n",
    "            test_data = data[cutoff:test_end_time]\n",
    "            test_common_predictors = common_predictors[cutoff:test_end_time]\n",
    "            test_specific_predictors = specific_predictors[\n",
    "                cutoff:test_end_time\n",
    "            ]\n",
    "            cv_batches.append(\n",
    "                (\n",
    "                    training_data,\n",
    "                    training_common_predictors,\n",
    "                    training_specific_predictors,\n",
    "                    test_data,\n",
    "                    test_common_predictors,\n",
    "                    test_specific_predictors,\n",
    "                )\n",
    "            )\n",
    "            test_end_time = cutoff\n",
    "            cutoff = test_end_time - prediction_time\n",
    "        self.cv_batches = cv_batches\n",
    "        self.models = {}\n",
    "        print(\n",
    "            \"Created a RollingValidator with {} cross-validation batches.\".format(\n",
    "                len(cv_batches)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def test_modelclass(self, modelclass, print_progress=False):\n",
    "        test_errors = []\n",
    "        training_errors = []\n",
    "        test_predictions = []\n",
    "        training_predictions = []\n",
    "        for (i, cv_batch,) in enumerate(self.cv_batches):\n",
    "            (\n",
    "                training_data,\n",
    "                training_common_predictors,\n",
    "                training_specific_predictors,\n",
    "                test_data,\n",
    "                test_common_predictors,\n",
    "                test_specific_predictors,\n",
    "            ) = cv_batch\n",
    "            if print_progress:\n",
    "                print(\"Training for batch {}.\".format(i))\n",
    "            model = modelclass()\n",
    "            model.train(\n",
    "                training_data,\n",
    "                training_common_predictors,\n",
    "                training_specific_predictors,\n",
    "            )\n",
    "            if print_progress:\n",
    "                print(\"Predicting for batch {}.\".format(i))\n",
    "            test_prediction = model.predict(\n",
    "                test_common_predictors, test_specific_predictors\n",
    "            )\n",
    "            training_prediction = model.predict(\n",
    "                training_common_predictors, training_specific_predictors\n",
    "            )\n",
    "            test_error = test_prediction - test_data\n",
    "            training_error = training_prediction - training_data\n",
    "            test_errors.append(test_error)\n",
    "            training_errors.append(training_error)\n",
    "            test_predictions.append(test_prediction)\n",
    "            training_predictions.append(training_predictions)\n",
    "        test_mae = pd.concat(test_errors).abs().mean()\n",
    "        training_mae = pd.concat(training_errors).abs().mean()\n",
    "        self.models[modelclass.classname] = {\n",
    "            \"test_mae\": test_mae,\n",
    "            \"training_mae\": training_mae,\n",
    "            \"test_errors\": test_errors,\n",
    "            \"training_errors\": training_errors,\n",
    "            \"test_predictions\": test_predictions,\n",
    "            \"training_predictions\": training_predictions,\n",
    "        }\n",
    "        return test_mae.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_dummies = pd.get_dummies(times.dt.weekday_name)\n",
    "week_dummies = pd.get_dummies(times.dt.week)\n",
    "hour_dummies = pd.get_dummies(times.dt.hour)\n",
    "hour_dummies = hour_dummies.rename(\n",
    "    columns={c: \"Hour {}\".format(c) for c in hour_dummies.columns}\n",
    ")\n",
    "week_dummies = week_dummies.rename(\n",
    "    columns={c: \"Week {}\".format(c) for c in week_dummies.columns}\n",
    ")\n",
    "predictors_dum = pd.concat(\n",
    "    [week_dummies, hour_dummies, weekday_dummies,], axis=1,\n",
    ")\n",
    "\n",
    "day_angles = 2 * np.pi * times.dt.hour / 24\n",
    "year_angles = (\n",
    "    2 * np.pi * times.dt.week / 52\n",
    ")  # TODO Should we do this by day or week or month?\n",
    "predictors_trig = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Year sine\": np.sin(year_angles),\n",
    "                \"Year cosine\": np.cos(year_angles),\n",
    "            }\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            {\"Day sine\": np.sin(day_angles), \"Day cosine\": np.cos(day_angles)}\n",
    "        ),\n",
    "        weekday_dummies,\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\n",
    "    (\"Waterloo Station 3, Waterloo\", \"Start\"),\n",
    "    (\"Hyde Park Corner, Hyde Park\", \"End\"),\n",
    "    (\"Wenlock Road , Hoxton\", \"End\"),\n",
    "]\n",
    "# test_columns = sum(\n",
    "#     [[(s, es) for s in test_stations] for es in (\"End\", \"Start\")], []\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly_rolling = changes.rolling(\"7d\").mean()\n",
    "# weekly_rolling = weekly_rolling - weekly_rolling.mean()\n",
    "# weekly_rolling = weekly_rolling / weekly_rolling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekoffset = events_by_station.shift(freq=pd.Timedelta(\"7d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = weekoffset.index.min()\n",
    "last_time = events_by_station.index.max()\n",
    "data = events_by_station.loc[first_time:last_time, test_columns]\n",
    "weekoffset = weekoffset.reindex(\n",
    "    data.index, method=\"nearest\"\n",
    ")  # TODO Is \"nearest\" good?\n",
    "# weekly_rolling = weekly_rolling[first_time:last_time]\n",
    "predictors_trig = predictors_trig.loc[first_time:last_time, :]\n",
    "predictors_dum = predictors_dum.loc[first_time:last_time, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a RollingValidator with 6 cross-validation batches.\n",
      "Created a RollingValidator with 6 cross-validation batches.\n"
     ]
    }
   ],
   "source": [
    "specific_predictors = weekoffset[test_columns]\n",
    "min_training_time = 2 * pd.Timedelta(\"365d\")\n",
    "prediction_time = 0.5 * pd.Timedelta(\"365d\")\n",
    "rv_trig = RollingValidator(\n",
    "    data,\n",
    "    predictors_trig,\n",
    "    specific_predictors,\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")\n",
    "rv_dum = RollingValidator(\n",
    "    data,\n",
    "    predictors_dum,\n",
    "    specific_predictors,\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a RollingValidator with 5 cross-validation batches.\n",
      "Created a RollingValidator with 5 cross-validation batches.\n"
     ]
    }
   ],
   "source": [
    "# For debugging\n",
    "dbg_timerange = slice(\"2017-01-01\", None)\n",
    "min_training_time = 2 * pd.Timedelta(\"30d\")\n",
    "prediction_time = 0.5 * pd.Timedelta(\"30d\")\n",
    "rv_trig = RollingValidator(\n",
    "    data[dbg_timerange],\n",
    "    predictors_trig[dbg_timerange],\n",
    "    specific_predictors[dbg_timerange],\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")\n",
    "rv_dum = RollingValidator(\n",
    "    data[dbg_timerange],\n",
    "    predictors_dum[dbg_timerange],\n",
    "    specific_predictors[dbg_timerange],\n",
    "    min_training_time,\n",
    "    prediction_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMean:\n",
    "    classname = \"SimpleMean\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, data, common_predictors, specific_predictors):\n",
    "        mean = pd.DataFrame(data.mean())\n",
    "        self.model = mean\n",
    "\n",
    "    def predict(self, common_predictors, specific_predictors):\n",
    "        mean = self.model\n",
    "        index = common_predictors.index\n",
    "        predictions = mean.T.apply(lambda x: [x[0]] * len(index)).set_index(\n",
    "            index\n",
    "        )\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastWeek:\n",
    "    classname = \"LastWeek\"\n",
    "\n",
    "    def train(self, data, common_predictors, specific_predictors):\n",
    "        pass\n",
    "\n",
    "    def predict(self, common_predictors, specific_predictors):\n",
    "        predictions = specific_predictors\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Linear are bad because all time variation has to be essentially sinusoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericModel:\n",
    "    # Place-holders for subclasses to replace.\n",
    "    regressor = None\n",
    "    classname = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.std = None\n",
    "\n",
    "    @classmethod\n",
    "    def normalize_predictor(cls, predictor):\n",
    "        return predictor, std\n",
    "\n",
    "    def train(self, data, common_predictors, specific_predictors):\n",
    "        if specific_predictors is not None:\n",
    "            std = specific_predictors.std()\n",
    "            specific_predictors = specific_predictors / std\n",
    "            self.std = std\n",
    "\n",
    "        for c in data.columns:\n",
    "            if specific_predictors is not None and c in specific_predictors:\n",
    "                predictors = pd.concat(\n",
    "                    [common_predictors, specific_predictors[c]], axis=1\n",
    "                )\n",
    "            else:\n",
    "                predictors = common_predictors\n",
    "            model = self.regressor()\n",
    "            model.fit(predictors, data[c])\n",
    "            self.model[c] = model\n",
    "\n",
    "    def predict(self, common_predictors, specific_predictors):\n",
    "        if specific_predictors is not None:\n",
    "            specific_predictors = specific_predictors / self.std\n",
    "        model = self.model\n",
    "        index = common_predictors.index\n",
    "        predictions = pd.DataFrame({\"Time\": index}).set_index(\"Time\")\n",
    "        for c, m in model.items():\n",
    "            if specific_predictors is not None and c in specific_predictors:\n",
    "                predictors = pd.concat(\n",
    "                    [common_predictors, specific_predictors[c]], axis=1\n",
    "                )\n",
    "            else:\n",
    "                predictors = common_predictors\n",
    "            predictions[c] = m.predict(predictors)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(GenericModel):\n",
    "    classname = \"Linear\"\n",
    "    regressor = linear_model.Ridge\n",
    "\n",
    "\n",
    "class LinearSVR(GenericModel):\n",
    "    classname = \"LinearSVR\"\n",
    "    regressor = lambda x: svm.LinearSVR(max_iter=5000)\n",
    "\n",
    "\n",
    "class KNeighbors(GenericModel):\n",
    "    classname = \"KNeighbors\"\n",
    "    regressor = lambda x: neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=5, weights=\"distance\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SVRrbf(GenericModel):\n",
    "    classname = \"SVRrbf\"\n",
    "    regressor = lambda x: svm.SVR(kernel=\"rbf\", cache_size=500)\n",
    "\n",
    "\n",
    "class SVRpoly(GenericModel):\n",
    "    classname = \"SVRpoly\"\n",
    "    regressor = lambda x: svm.SVR(kernel=\"poly\", cache_size=500)\n",
    "\n",
    "\n",
    "class SVRsigmoid(GenericModel):\n",
    "    classname = \"SVRsigmoid\"\n",
    "    regressor = lambda x: svm.SVR(kernel=\"sigmoid\", cache_size=500)\n",
    "\n",
    "\n",
    "# class GaussianNB(GenericModel):\n",
    "#     classname = \"GaussianNB\"\n",
    "#     regressor = lambda x: naive_bayes.GaussianNB()\n",
    "\n",
    "\n",
    "class DecisionTree(GenericModel):\n",
    "    classname = \"DecisionTree\"\n",
    "    regressor = lambda x: tree.DecisionTreeRegressor(\n",
    "        criterion=\"mae\", max_depth=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that linear models probably fit to squared error, we measure absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KernelRidge also can't handle this amount of training data with chocking on RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diffmodelclass(modelclass):\n",
    "    class DiffModel(modelclass):\n",
    "        parent = modelclass\n",
    "        classname = \"DiffModel({})\".format(modelclass.classname)\n",
    "\n",
    "        def train(self, data, common_predictors, specific_predictors):\n",
    "            data = data.copy()\n",
    "            for c in data.columns:\n",
    "                data[c] = data[c] - specific_predictors[c]\n",
    "            super().train(data, common_predictors, None)\n",
    "\n",
    "        def predict(self, common_predictors, specific_predictors):\n",
    "            predictions = super().predict(common_predictors, None)\n",
    "            for c in predictions.columns:\n",
    "                predictions[c] = predictions[c] + specific_predictors[c]\n",
    "            return predictions\n",
    "\n",
    "    return DiffModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiffSimpleMean = make_diffmodelclass(SimpleMean)\n",
    "DiffLinear = make_diffmodelclass(Linear)\n",
    "DiffKNeighbors = make_diffmodelclass(KNeighbors)\n",
    "DiffLinearSVR = make_diffmodelclass(LinearSVR)\n",
    "# DiffGaussianNB = make_diffmodelclass(GaussianNB)\n",
    "DiffDecisionTree = make_diffmodelclass(DecisionTree)\n",
    "DiffSVRrbf = make_diffmodelclass(SVRrbf)\n",
    "DiffSVRpoly = make_diffmodelclass(SVRpoly)\n",
    "DiffSVRsigmoid = make_diffmodelclass(SVRsigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for batch 0.\n",
      "Predicting for batch 0.\n",
      "Training for batch 1.\n",
      "Predicting for batch 1.\n",
      "Training for batch 2.\n",
      "Predicting for batch 2.\n",
      "Training for batch 3.\n",
      "Predicting for batch 3.\n",
      "Training for batch 4.\n",
      "Predicting for batch 4.\n",
      "49.37012195121951\n"
     ]
    }
   ],
   "source": [
    "# print(rv_dum.test_modelclass(DiffLinear, print_progress=True))\n",
    "# print(rv_trig.test_modelclass(DiffKNeighbors, print_progress=True))\n",
    "# print(rv_trig.test_modelclass(DiffDecisionTree, print_progress=True))\n",
    "print(rv_trig.test_modelclass(GaussianNB, print_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMean\n",
      "trig mae: 27.726   (took 0.0 mins)\n",
      "dumm mae: 27.726   (took 0.0 mins)\n",
      "\n",
      "LastWeek\n",
      "trig mae: 13.249   (took 0.0 mins)\n",
      "dumm mae: 13.249   (took 0.0 mins)\n",
      "\n",
      "Linear\n",
      "trig mae: 16.947   (took 0.0 mins)\n",
      "dumm mae: 15.339   (took 0.0 mins)\n",
      "\n",
      "KNeighbors\n",
      "trig mae: 12.620   (took 0.0 mins)\n",
      "dumm mae: 11.892   (took 0.1 mins)\n",
      "\n",
      "LinearSVR\n",
      "trig mae: 13.469   (took 0.0 mins)\n",
      "dumm mae: 13.652   (took 0.0 mins)\n",
      "\n",
      "DecisionTree\n",
      "trig mae: 15.369   (took 0.0 mins)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-0f79e6f7a7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_modelclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-f7756bbf18e8>\u001b[0m in \u001b[0;36mtest_modelclass\u001b[0;34m(self, modelclass, print_progress)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mtraining_common_predictors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mtraining_specific_predictors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             )\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-c0a03faedd22>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, common_predictors, specific_predictors)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_predictors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "classes = [\n",
    "    SimpleMean,\n",
    "    LastWeek,\n",
    "    Linear,\n",
    "    KNeighbors,\n",
    "    LinearSVR,\n",
    "    #     GaussianNB,\n",
    "    DecisionTree,\n",
    "    SVRrbf,\n",
    "    SVRpoly,\n",
    "    #     SVRsigmoid,\n",
    "    DiffSimpleMean,\n",
    "    DiffLinear,\n",
    "    DiffKNeighbors,\n",
    "    DiffLinearSVR,\n",
    "    #     DiffGaussianNB,\n",
    "    DiffDecisionTree,\n",
    "    DiffSVRrbf,\n",
    "    DiffSVRpoly,\n",
    "    #     DiffSVRsigmoid,\n",
    "]\n",
    "for modelclass in classes:\n",
    "    print(modelclass.classname)\n",
    "    for rv, rv_name in ((rv_trig, \"trig\"), (rv_dum, \"dumm\")):\n",
    "        start = timer()\n",
    "        try:\n",
    "            err = rv.test_modelclass(modelclass)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        stop = timer()\n",
    "        time = (stop - start) / 60\n",
    "        print(\"{} mae: {:.3f}   (took {:.1f} mins)\".format(rv_name, err, time))\n",
    "        with open(\"latest_rv_dum.p\", \"wb\") as f:\n",
    "            pickle.dump(rv_dum, f)\n",
    "        with open(\"latest_rv_trig.p\", \"wb\") as f:\n",
    "            pickle.dump(rv_trig, f)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"latest_rv_dum.p\", \"rb\") as f:\n",
    "    rv_dum = pickle.load(f)\n",
    "with open(\"latest_rv_trig.p\", \"rb\") as f:\n",
    "    rv_trig = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMean               : 27.726   23.923\n",
      "LastWeek                 : 13.249   10.835\n",
      "Linear                   : 15.339   11.745\n",
      "KNeighbors               : 11.892   0.000\n",
      "LinearSVR                : 13.652   9.624\n",
      "GaussianNB               : 21.659   18.011\n",
      "DecisionTree             : 15.035   9.533\n",
      "SVRrbf                   : 16.822   11.754\n",
      "SVRpoly                  : 15.832   8.325\n",
      "SVRsigmoid               : 50.334   40.160\n",
      "DiffModel(SimpleMean)    : 13.945   11.551\n",
      "DiffModel(Linear)        : 15.654   12.668\n",
      "DiffModel(KNeighbors)    : 13.736   0.000\n",
      "DiffModel(LinearSVR)     : 13.365   10.769\n",
      "DiffModel(GaussianNB)    : 28.404   19.081\n",
      "DiffModel(DecisionTree)  : 13.911   10.604\n",
      "DiffModel(SVRrbf)        : 13.363   10.191\n",
      "DiffModel(SVRpoly)       : 13.398   9.772\n",
      "DiffModel(SVRsigmoid)    : 13.570   12.575\n"
     ]
    }
   ],
   "source": [
    "for k, v in rv_dum.models.items():\n",
    "    test_mae = v[\"test_mae\"].sum()\n",
    "    training_mae = v[\"training_mae\"].sum()\n",
    "    print(\"{:25}: {:.3f}   {:.3f}\".format(k, test_mae, training_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c7ecab513a446bb27bdb25f61517b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57d6d9a050>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = rv_trig\n",
    "plot_column = (\"Hyde Park Corner, Hyde Park\", \"End\")\n",
    "# plot_columns = [(\"Wenlock Road , Hoxton\", \"End\")]\n",
    "# plot_columns = [(\"Waterloo Station 3, Waterloo\",  \"Start\")]\n",
    "modelclass = KNeighbors\n",
    "err = pd.concat(rv.models[modelclass.classname][\"test_errors\"]).sort_index()\n",
    "pred = pd.concat(rv.models[modelclass.classname][\"test_predictions\"]).sort_index()\n",
    "truth = pd.concat([l[3] for l in rv.cv_batches]).sort_index()\n",
    "plt.figure()\n",
    "plt.plot(truth[plot_column], pred[plot_column], ls=\"\", marker=\"*\", ms=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class '__main__.KNeighbors'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-660265d720ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot_columns = [(\"Waterloo Station 3, Waterloo\",  \"Start\")]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodelclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_errors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelclass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_predictions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class '__main__.KNeighbors'>"
     ]
    }
   ],
   "source": [
    "rv = rv_dum\n",
    "plot_columns = [(\"Hyde Park Corner, Hyde Park\", \"End\")]\n",
    "# plot_columns = [(\"Wenlock Road , Hoxton\", \"End\")]\n",
    "# plot_columns = [(\"Waterloo Station 3, Waterloo\",  \"Start\")]\n",
    "modelclass = KNeighbors\n",
    "err = pd.concat(rv.models[modelclass][\"test_errors\"]).sort_index()\n",
    "pred = pd.concat(rv.models[modelclass][\"test_predictions\"]).sort_index()\n",
    "truth = pd.concat([l[3] for l in rv.cv_batches]).sort_index()\n",
    "plt.figure()\n",
    "plt.plot(truth[plot_columns])\n",
    "plt.plot(pred[plot_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2848: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  raw_cell, store_history, silent, shell_futures)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff5a0d6d484495ab30f3bb107954d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2848: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  raw_cell, store_history, silent, shell_futures)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f572ab8b544a2aa37307a32889233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2848: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  raw_cell, store_history, silent, shell_futures)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa739383d1347dba18339dbe0a9d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in test_columns:\n",
    "    datac = events_by_station[c]\n",
    "    datac = datac / datac.mean()\n",
    "    # data = data / data.rolling(\"365d\").mean()\n",
    "    datac.rolling(\"14d\").mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f50f87764f4e10962075aa3b5ada14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f57d69e4710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f57d7015450>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_by_time.groupby(times.dt.date).sum().hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "043db0f5d282460abaa78bc78902fd80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d24e0d70777480a8b361c85b3ff3b0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0e902aa6e0c649768cff1ad163c0af1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21e6e52689734dfda916a54753700dc1": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_3ed1c9b1437e4422b299e4a74186a21d",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "21f83851c0714cab8e97665bdc8652cf": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_47fb5fd65ad34632826c0f3a1d1a5bbe",
       "toolbar": "IPY_MODEL_f6b4598abe634d14b42384412aafbfec",
       "toolbar_position": "left"
      }
     },
     "27f50f87764f4e10962075aa3b5ada14": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_e4e8bf74d1dd4d9684396493dc876454",
       "toolbar": "IPY_MODEL_eff15dcbfb7e4fff9aa72c67672aa099",
       "toolbar_position": "left"
      }
     },
     "2e348cc88d51464391d0f0df42ef71af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a6c4a7166344ed4b5e117e29b3ba200": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_0d24e0d70777480a8b361c85b3ff3b0e",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "3ed1c9b1437e4422b299e4a74186a21d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "47fb5fd65ad34632826c0f3a1d1a5bbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5327e4879a1c4133b82ccb874f259d3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "54be81d504e345228abd47f1d6a35e95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "57e1dc7f5a4344adbb056946a61cd80f": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_8af621bc7efd4ab8a26278ef9ebc3e0d",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "67aa0d7daad5424dbbfe6493607a84e4": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_f5864984ad394769b0703c82a408742c",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "73de4fb68302427a8a2873fb1ba23b7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7cc13f27b6d64159a889177973092abd": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c1efa06017e44c529f06d8b3cec35899",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "8af621bc7efd4ab8a26278ef9ebc3e0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8fa739383d1347dba18339dbe0a9d2bf": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_d8583db488464404b235a2620c8b9b00",
       "toolbar": "IPY_MODEL_cb7bdf8dd87c4a5f9d3989b1adca30a7",
       "toolbar_position": "left"
      }
     },
     "923f5d7445314de6bf6b18ac2b229416": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_2e348cc88d51464391d0f0df42ef71af",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "aff5a0d6d484495ab30f3bb107954d18": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_043db0f5d282460abaa78bc78902fd80",
       "toolbar": "IPY_MODEL_7cc13f27b6d64159a889177973092abd",
       "toolbar_position": "left"
      }
     },
     "c1efa06017e44c529f06d8b3cec35899": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c320f9deb6f742ad890641b7df5bbbbd": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_cec56afadf5d4abca6686218486edfb9",
       "toolbar": "IPY_MODEL_67aa0d7daad5424dbbfe6493607a84e4",
       "toolbar_position": "left"
      }
     },
     "c3bc1041bf9748bf95e96f6983389413": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c7c7ecab513a446bb27bdb25f61517b1": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_5327e4879a1c4133b82ccb874f259d3e",
       "toolbar": "IPY_MODEL_21e6e52689734dfda916a54753700dc1",
       "toolbar_position": "left"
      }
     },
     "cb7bdf8dd87c4a5f9d3989b1adca30a7": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_e4c18a6a74a3478598782a9a29b4d2fe",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "cec56afadf5d4abca6686218486edfb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8583db488464404b235a2620c8b9b00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4c18a6a74a3478598782a9a29b4d2fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4e8bf74d1dd4d9684396493dc876454": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eff15dcbfb7e4fff9aa72c67672aa099": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_73de4fb68302427a8a2873fb1ba23b7d",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "f07eab34a767425f9eba8e7381b70a12": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_54be81d504e345228abd47f1d6a35e95",
       "toolbar": "IPY_MODEL_3a6c4a7166344ed4b5e117e29b3ba200",
       "toolbar_position": "left"
      }
     },
     "f194eb5e28544fc881a6cfcdf16964fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5864984ad394769b0703c82a408742c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6b4598abe634d14b42384412aafbfec": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c3bc1041bf9748bf95e96f6983389413",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "f89f572ab8b544a2aa37307a32889233": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_0e902aa6e0c649768cff1ad163c0af1d",
       "toolbar": "IPY_MODEL_57e1dc7f5a4344adbb056946a61cd80f",
       "toolbar_position": "left"
      }
     },
     "fb83a0301c5a459d8a4907eac95e9941": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.5.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_f194eb5e28544fc881a6cfcdf16964fc",
       "toolbar": "IPY_MODEL_923f5d7445314de6bf6b18ac2b229416",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
